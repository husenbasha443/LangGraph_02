{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c53638cb",
   "metadata": {},
   "source": [
    "## Agentic RAG System\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2334cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\LangGraphSeries\\module01\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model = ChatGroq(model=\"llama-3.1-8b-instant\")                 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4eca52f",
   "metadata": {},
   "source": [
    "## Blog 1 --->LangGraph Blog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c3569a",
   "metadata": {},
   "source": [
    "#### Craete a Retrievers(Vector DBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e068d4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61eb88da",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LangGraph Blog URLS\n",
    "\n",
    "urls = [\n",
    "    \"https://www.langchain.com/langgraph\",\n",
    "    \"https://www.geeksforgeeks.org/machine-learning/what-is-langgraph/\",\n",
    "    \"https://www.ibm.com/think/topics/langgraph\",\n",
    "    \"https://realpython.com/langgraph-python/\"\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "664cc2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load The URL's\n",
    "\n",
    "docs = WebBaseLoader(web_paths=urls)\n",
    "loader = docs.load()\n",
    " \n",
    "\n",
    "##Splitter using loader\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size = 500,chunk_overlap=200)\n",
    "final_split = splitter.split_documents(loader)\n",
    "final_split[:2]\n",
    "\n",
    "### Convert into Vectors\n",
    "embeddinds = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "text_list = [doc.page_content for doc in final_split]\n",
    "vector = embeddinds.embed_documents(text_list)\n",
    "\n",
    "## Store into Vector DB\n",
    "store = FAISS.from_documents(documents=final_split,embedding=embeddinds)\n",
    "store.save_local(\"./husen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "693e8da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='c3575ce3-3c0d-4e71-890c-8dd1a79775bc', metadata={'source': 'https://www.geeksforgeeks.org/machine-learning/what-is-langgraph/', 'title': 'What is LangGraph? - GeeksforGeeks', 'description': 'Your All-in-One Learning Portal: GeeksforGeeks is a comprehensive educational platform that empowers learners across domains-spanning computer science and programming, school education, upskilling, commerce, software tools, competitive exams, and more.', 'language': 'en-US'}, page_content='What is LangGraph? - GeeksforGeeks\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to content'),\n",
       " Document(id='3da63293-d5bf-446c-8439-f4e1d084d8f8', metadata={'source': 'https://www.ibm.com/think/topics/langgraph', 'title': 'What is LangGraph? | IBM', 'description': 'Stay ahead of the curve with AI-powered solutions that enhance productivity and streamline workflows using WatsonX and LangGraph.', 'language': 'en'}, page_content='LangGraph workflow'),\n",
       " Document(id='539112eb-baa7-4720-b749-9d53200c47b0', metadata={'source': 'https://www.ibm.com/think/topics/langgraph', 'title': 'What is LangGraph? | IBM', 'description': 'Stay ahead of the curve with AI-powered solutions that enhance productivity and streamline workflows using WatsonX and LangGraph.', 'language': 'en'}, page_content='LangGraph, created by LangChain, is an open source AI agent framework designed to build, deploy and manage complex generative AI agent workflows. It provides a set of tools and libraries that enable users to create, run and optimize large language models (LLMs) in a scalable and efficient manner. At its core, LangGraph uses the power of graph-based architectures to model and manage the intricate relationships between various components of an AI agent workflow.'),\n",
       " Document(id='7464247d-3ca5-417b-8771-e6860940fddc', metadata={'source': 'https://www.ibm.com/think/topics/langgraph', 'title': 'What is LangGraph? | IBM', 'description': 'Stay ahead of the curve with AI-powered solutions that enhance productivity and streamline workflows using WatsonX and LangGraph.', 'language': 'en'}, page_content='Shallow learning curve: LangGraph Studio is not needed to access LangGraph. However, by using LangGraph Studio’s visual interface, users can focus on designing their workflows without getting bogged down in code.\\nImproved collaboration: LangGraph Studio enables the sharing of workflows with others, whether that’s a team of developers or a client.')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.similarity_search(\"What is LangGraph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6f2baee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001B287A6B980>, search_kwargs={})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Perform as Retriever\n",
    "\n",
    "retrieval = store.as_retriever()\n",
    "retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05489fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='3da63293-d5bf-446c-8439-f4e1d084d8f8', metadata={'source': 'https://www.ibm.com/think/topics/langgraph', 'title': 'What is LangGraph? | IBM', 'description': 'Stay ahead of the curve with AI-powered solutions that enhance productivity and streamline workflows using WatsonX and LangGraph.', 'language': 'en'}, page_content='LangGraph workflow'),\n",
       " Document(id='1250a76f-88a7-4c51-8a7d-c8092184583d', metadata={'source': 'https://www.ibm.com/think/topics/langgraph', 'title': 'What is LangGraph? | IBM', 'description': 'Stay ahead of the curve with AI-powered solutions that enhance productivity and streamline workflows using WatsonX and LangGraph.', 'language': 'en'}, page_content='Delve deeper into the world of LangGraph by exploring its key features, benefits and use cases. By the end of this article, you will have the knowledge and resources to take the next steps with LangGraph.'),\n",
       " Document(id='f6f53ff2-2daf-4eed-a3df-86b869d0aa18', metadata={'source': 'https://www.ibm.com/think/topics/langgraph', 'title': 'What is LangGraph? | IBM', 'description': 'Stay ahead of the curve with AI-powered solutions that enhance productivity and streamline workflows using WatsonX and LangGraph.', 'language': 'en'}, page_content='Key components of LangGraph\\r\\n    \\n\\n\\n\\nLet’s begin by first understanding the key components that make up LangGraph. The framework is built around several key components that work together to enable users to create and manage complex AI workflows. These components include:\\n\\n\\nMonitoring mechanism'),\n",
       " Document(id='fe5a35fb-21ee-4f66-9bba-9576dae628e4', metadata={'source': 'https://www.geeksforgeeks.org/machine-learning/what-is-langgraph/', 'title': 'What is LangGraph? - GeeksforGeeks', 'description': 'Your All-in-One Learning Portal: GeeksforGeeks is a comprehensive educational platform that empowers learners across domains-spanning computer science and programming, school education, upskilling, commerce, software tools, competitive exams, and more.', 'language': 'en-US'}, page_content='What is LangGraph?\\n\\n\\n\\nLast Updated : \\n12 Dec, 2025\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nComments\\n\\n\\n\\n\\n\\n\\n\\nImprove\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSuggest changes\\n\\n\\n\\n\\n\\n\\n1 Likes\\n\\n\\n\\nLike\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nReport')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Invoke the retrieval\n",
    "\n",
    "retrieval.invoke(\"LangGraph Features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a732b260",
   "metadata": {},
   "source": [
    "#### Retriieval to Retrieval Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ce8e519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredTool(name='retrive data from store db ', description='Search and run information about LangGraph', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=<function create_retriever_tool.<locals>.func at 0x000001B28719D8A0>, coroutine=<function create_retriever_tool.<locals>.afunc at 0x000001B28719C540>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.tools import create_retriever_tool\n",
    "\n",
    "langGraph_retrieval_tool = create_retriever_tool(\n",
    "    retrieval,\n",
    "    \"retrive data from store db \",\n",
    "    \"Search and run information about LangGraph\"\n",
    "    \n",
    ")\n",
    "langGraph_retrieval_tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d783298d",
   "metadata": {},
   "source": [
    "## Blog--->02  ---- LangChain Blog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3123985",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0622748d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://www.geeksforgeeks.org/artificial-intelligence/introduction-to-langchain/', 'title': 'Introduction to LangChain - GeeksforGeeks', 'description': 'Your All-in-One Learning Portal: GeeksforGeeks is a comprehensive educational platform that empowers learners across domains-spanning computer science and programming, school education, upskilling, commerce, software tools, competitive exams, and more.', 'language': 'en-US'}, page_content='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nIntroduction to LangChain - GeeksforGeeks\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to content\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCoursesDSA / PlacementsGATE PrepML & Data ScienceDevelopmentCloud / DevOpsProgramming LanguagesAll CoursesTutorialsPythonJavaDSAML & Data ScienceInterview CornerProgramming LanguagesWeb DevelopmentGATECS SubjectsDevOpsSchool LearningSoftware and ToolsPracticePractice Coding ProblemsNation Skillup- Ending Soon!Problem of the DayAI Agent Workshop (with Certification)Study Abroad ChampionshipJobsApply Now!Post JobsJobs UpdatesApply for Campus Mantri\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNotifications\\n\\nMark all as read\\n\\n\\n\\n\\n\\nAll\\n\\n\\n\\n\\n\\n \\n\\nView All\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNotifications\\n\\n\\n\\nMark all as read\\n\\n\\n\\n\\n\\n\\nAll\\n\\n\\nUnread\\n\\n\\nRead\\n\\n\\n\\n\\n\\r\\n                        You\\'re all caught up!!\\r\\n                    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nArtificial IntelligenceInterview QuestionsProject IdeasSearch AlgorithmsLocal Search AlgorithmGenerative AIData ScienceMachine LearningDeep LearningML-ProjectsRobotics \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSign In\\n\\n\\n▲\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nOpen In App\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTechnical Scripter ExploreIntroduction to AIWhat is Artificial Intelligence (AI)Types of Artificial Intelligence (AI)Types of AI Based on FunctionalitiesAgents in AIArtificial intelligence vs Machine Learning vs Deep LearningProblem Solving in Artificial IntelligenceTop 20 Applications of Artificial Intelligence (AI) in 2025AI ConceptsSearch Algorithms in AILocal Search Algorithm in Artificial IntelligenceAdversarial Search Algorithms in Artificial Intelligence (AI)Constraint Satisfaction Problems (CSP) in Artificial IntelligenceKnowledge Representation in AIFirst-Order Logic in Artificial IntelligenceReasoning Mechanisms in AIMachine Learning in AIMachine Learning TutorialDeep Learning TutorialNatural Language Processing (NLP) TutorialComputer Vision TutorialRobotics and AIArtificial Intelligence in RoboticsWhat is Robotics Process AutomationAutomated Planning in AIAI in TransportationAI in Manufacturing : Revolutionizing the IndustryGenerative AIWhat is Generative AI?Generative Adversarial Network (GAN)Cycle Generative Adversarial Network (CycleGAN)StyleGAN - Style Generative Adversarial NetworksIntroduction to Generative Pre-trained Transformer (GPT)BERT Model - NLPGenerative AI Applications AI PracticeTop Artificial Intelligence(AI) Interview Questions and AnswersTop Generative AI and LLM  Interview Question with Answer30+ Best Artificial Intelligence Project Ideas with Source Code [2025 Updated]Generative AIExplore \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nIntroduction to LangChain\\n\\n\\n\\nLast Updated : \\n12 Dec, 2025\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nComments\\n\\n\\n\\n\\n\\n\\n\\nImprove\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSuggest changes\\n\\n\\n\\n\\n\\n\\n14 Likes\\n\\n\\n\\nLike\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nReport\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLangChain is an open-source framework designed to simplify the creation of applications using large language models (LLMs). It provides a standard interface for integrating with other tools and end-to-end chains for common applications. It helps AI developers connect LLMs such as GPT-4 with external data and computation. This framework comes for both Python and JavaScript.Key benefits include: Modular Workflow: Simplifies chaining LLMs together for reusable and efficient workflows.Prompt Management: Offers tools for effective prompt engineering and memory handling.Ease of Integration: Streamlines the process of building LLM-powered applications.Key Components of LangChainLets see various components of Langchain: 1. Chains: Chains define sequences of actions, where each step can involve querying an LLM, manipulating data or interacting with external tools. There are two types:Simple Chains: A single LLM invocation.Multi-step Chains: Multiple LLMs or actions combined, where each step can take the output from the previous step.2. Prompt Management: LangChain facilitates managing and customizing prompts passed to the LLM. Developers can use PromptTemplates to define how inputs and outputs are formatted before being passed to the model. It also simplifies tasks like handling dynamic variables and prompt engineering, making it easier to control the LLM\\'s behavior.3. Agents: Agents are autonomous systems within LangChain that take actions based on input data. They can call external APIs or query databases dynamically, making decisions based on the situation. These agents leverage LLMs for decision-making, allowing them to respond intelligently to changing input.4. Vector Database: LangChain integrates with a vector database which is used to store and search high-dimensional vector representations of data. This is important for performing similarity searches, where the LLM converts a query into a vector and compares it against the vectors in the database to retrieve relevant information.Vector database plays a key role in tasks like document retrieval, knowledge base integration or context-based search providing the model with dynamic, real-time data to enhance responses.5. Models: LangChain is model-agnostic meaning it can integrate with different LLMs such as OpenAI\\'s GPT, Hugging Face models, DeepSeek R1 and more. This flexibility allows developers to choose the best model for their use case while benefiting from LangChain’s architecture.6. Memory Management: LangChain supports memory management allowing the LLM to \"remember\" context from previous interactions. This is especially useful for creating conversational agents that need context across multiple inputs. The memory allows the model to handle sequential conversations, keeping track of prior exchanges to ensure the system responds appropriately.How LangChain Works?LangChain follows a structured pipeline that integrates user queries, data retrieval and response generation into seamless workflow. LangChain Pipeline1. User QueryThe process begins when a user submits a query or request. For example, a user might ask, “What’s the weather like today?” This query serves as the input to the LangChain pipeline.2. Vector Representation and Similarity SearchOnce the query is received, LangChain converts it into a\\xa0vector representation\\xa0using embeddings. This vector captures the semantic meaning of the query. The vector is then used to perform a\\xa0similarity search\\xa0in a\\xa0vector database. The goal is to find the most relevant information or context stored in the database that matches the user\\'s query.3. Fetching Relevant InformationBased on the similarity search, LangChain retrieves the most relevant data or context from the database. This step ensures that the language model has access to accurate and contextually appropriate information to generate a meaningful response.4. Generating a ResponseThe retrieved information is passed to the\\xa0language model\\xa0(e.g., OpenAI\\'s GPT, Anthropic\\'s Claude or others). The LLM processes the input and generates a response or takes an action based on the provided data. For example, if the query is about the weather, the LLM might generate a response like,\\xa0“Today’s weather is sunny with a high of 75°F.”The formatted response is returned to the user as the final output. The user receives a clear, accurate and contextually relevant answer to their query.Step-by-Step ImplementationLet\\'s implement a model using LangChain and OpenAI API:Step 1: Install the dependenciesWe will install all the required dependencies for our model.langchain: the core LangChain framework (chains, prompts, tools, memory, etc.).langchain-openai: OpenAI model wrapper for LangChain (GPT-3.5, GPT-4, etc.).python-dotenv: to securely manage our API keys inside a .env file.\\nPython\\n\\n!pip install langchain langchain-openai python-dotenv\\n\\nStep 2: Import LibrariesWe will import all the required libraries.os: interact with environment variables.load_dotenv: loads .env file values into our environment.OpenAI: lets us call OpenAI’s GPT models in LangChain.PromptTemplate: define structured prompts with placeholders.StrOutputParser: ensures model response is returned as clean string text.\\nPython\\n\\nimport os\\nfrom dotenv import load_dotenv\\nfrom langchain_openai import OpenAI\\nfrom langchain.prompts import PromptTemplate\\nfrom langchain_core.output_parsers import StrOutputParser\\n\\nStep 3: Load API KeyWe need to load the OpenAI API Key, but first we create a .env file to store our API key.\\n.env\\n\\nOPENAI_API_KEY = your_openai_api_key_here\\n\\nNow we use the os.getenv() function to securely fetch the API key. \\nPython\\n\\nload_dotenv()\\napi_key = os.getenv(\"OPENAI_API_KEY\")\\n\\nStep 4: Initialize the OpenAI LLMWe initialize the LLM model:temperature=0.7: controls creativity (0 = deterministic, 1 = very creative).openai_api_key=api_key: authenticates with OpenAI.\\nPython\\n\\nllm = OpenAI(\\n    temperature=0.7,\\n    openai_api_key=api_key\\n)\\n\\nStep 5: Run a Simple PromptWe will check by running a simple prompt..invoke(): sends prompt to LLM and returns text output.\\nPython\\n\\nprompt = \"Suggest me a skill that is in demand?\"\\nresponse = llm.invoke(prompt)\\nprint(\" Suggested Skill:\\\\n\", response)\\n\\nOutput:OutputStep 6: Create a Prompt TemplateWe create a dynamic prompt where {year} can be replaced with input values.\\nPython\\n\\ntemplate = \"Give me 3 career skills that are in high demand in {year}.\"\\nprompt_template = PromptTemplate.from_template(template)\\n\\nStep 7: Build a Chain with LCELLCEL (LangChain Expression Language):  It’s a new way to compose LLM workflows using a simple, chainable syntax with the | (pipe) operator.1. prompt_templateFills placeholders (like {year}) with actual inputs.Example: \"Give me 3 career skills in 2025.\"2. llmSends the formatted prompt to the OpenAI model.Example input: \"Give me 3 career skills in 2025.\"Example output: \"1. Data Analytics\\\\n2. AI/ML\\\\n3. Cybersecurity\"3. StrOutputParser()Cleans up and ensures the LLM’s response is returned as a string.\\nPython\\n\\nchain = prompt_template | llm | StrOutputParser()\\n\\nStep 8: Run the ChainWe run the chain to fetch results..invoke({\"year\": \"2025\"}) replaces {year} with 2025 in the prompt.Final formatted prompt: \"Give me 3 career skills that are in high demand in 2025.\"\\nPython\\n\\nresponse = chain.invoke({\"year\": \"2025\"})\\nprint(\"\\\\n Career Skills in 2025:\\\\n\", response)\\n\\nOutput: OutputApplications of LangChainLet\\'s see the applications of LangChain,Chatbots and Virtual Assistants: They can be designed to remember past interactions, connect with external APIs and deliver more natural, context-aware conversations.Document Question Answering: Users can query PDFs, research papers, contracts or enterprise documentation and get precise answers instead of manually searching.Knowledge Management Systems: They help organize and retrieve company knowledge by linking LLMs with structured and unstructured data, enabling intelligent search, summarization and recommendations.Workflow Automation: Complex multi-step processes like customer support ticket resolution, report generation or CRM updates can be automated seamlessly.Data Analysis and Business Intelligence (BI): Natural language queries can be translated into SQL, turning raw data into insights, charts or business reports with minimal effort.The LangChain framework is a great interface to develop interesting AI-powered applications and from personal assistants to prompt management as well as automating tasks. So, keep learning and keep developing powerful applications. \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCreate Quiz\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nIntroduction to Langchain\\n\\n \\n\\n\\n\\n\\n\\r\\n        Comment\\r\\n    \\n\\n\\n\\n\\n\\nN\\n\\n\\n\\n\\n\\nnamaldesign\\n\\n\\n\\n\\n\\n Follow\\n\\n\\n\\n\\n\\n\\n14\\n\\n\\nImprove\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\nN\\n\\n\\n\\n\\n \\n\\nnamaldesign \\n\\n\\n\\n\\n\\n Follow \\n\\n\\n\\n\\n\\n\\n\\n\\n14\\n\\n\\n\\nImprove\\n\\n\\n\\n\\n\\n\\nArticle Tags : \\n\\n\\nArtificial Intelligence\\n\\n\\nPython-Library\\n\\n\\nPython-Miscellaneous\\n\\n\\npython\\n\\n\\nChatGPT Prompts\\n\\n\\nOpenAI API\\n \\n+2 More\\n\\n\\n\\n\\n\\n\\n\\n\\nLike\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCorporate & Communications Address:\\n\\r\\n                      A-143, 7th Floor, Sovereign Corporate Tower, Sector- 136, Noida, Uttar Pradesh (201305)                    \\n\\n\\n\\n\\n\\nRegistered Address:\\r\\n                        K 061, Tower K, Gulshan Vivante Apartment, Sector 137, Noida, Gautam Buddh Nagar, Uttar Pradesh, 201305                      \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCompanyAbout UsLegalPrivacy PolicyCareersContact UsCorporate SolutionCampus Training ProgramExplorePOTDJob-A-ThonConnectBlogsNation Skill UpTutorialsProgramming LanguagesDSAWeb TechnologyAI, ML & Data ScienceDevOpsCS Core SubjectsGATESchool SubjectsSoftware and ToolsCoursesML and Data ScienceDSA and PlacementsWeb DevelopmentData ScienceProgramming LanguagesDevOps & CloudGATETrending TechnologiesOffline CentersNoidaBengaluruPuneHyderabadPatnaPreparation CornerInterview CornerAptitudePuzzlesGfG 160System Design \\n\\n\\n\\n\\n\\n\\n@GeeksforGeeks, Sanchhaya Education Private Limited, All rights reserved\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nImprovement\\n\\n\\n\\n\\n\\n\\n\\nSuggest changes\\n\\n\\n\\n\\n\\nSuggest Changes\\nHelp us improve. Share your suggestions to enhance the article. Contribute your expertise and make a difference in the GeeksforGeeks portal.\\n\\n\\n\\n\\n\\n\\n\\nCreate Improvement\\nEnhance the article with your expertise. Contribute to the GeeksforGeeks community and help create better learning resources for all.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSuggest Changes\\n\\n\\n\\n\\n\\n\\nmin 4 words, max Words Limit:1000\\n\\n\\n\\n\\nThank You!\\nYour suggestions are valuable to us.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWhat kind of Experience do you want to share?\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nInterview Experiences\\n\\n\\n\\n\\n\\n\\n\\nAdmission Experiences\\n\\n\\n\\n\\n\\n\\n\\nCareer Journeys\\n\\n\\n\\n\\n\\n\\n\\nWork Experiences\\n\\n\\n\\n\\n\\n\\n\\nCampus Experiences\\n\\n\\n\\n\\n\\n\\n\\nCompetitive Exam Experiences\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'),\n",
       " Document(metadata={'source': 'https://docs.langchain.com/oss/python/langchain/overview', 'title': 'LangChain overview - Docs by LangChain', 'language': 'en'}, page_content='LangChain overview - Docs by LangChainSkip to main contentDocs by LangChain home pageLangChain + LangGraphSearch...⌘KAsk AIGitHubTry LangSmithTry LangSmithSearch...NavigationLangChain overviewLangChainLangGraphDeep AgentsIntegrationsLearnReferenceContributePythonOverviewGet startedInstallQuickstartChangelogPhilosophyCore componentsAgentsModelsMessagesToolsShort-term memoryStreamingStructured outputMiddlewareOverviewBuilt-in middlewareCustom middlewareAdvanced usageGuardrailsRuntimeContext engineeringModel Context Protocol (MCP)Human-in-the-loopMulti-agentRetrievalLong-term memoryAgent developmentLangSmith StudioTestAgent Chat UIDeploy with LangSmithDeploymentObservabilityOn this page Create an agent Core benefitsLangChain overviewCopy pageCopy pageLangChain is the easiest way to start building agents and applications powered by LLMs. With under 10 lines of code, you can connect to OpenAI, Anthropic, Google, and more. LangChain provides a pre-built agent architecture and model integrations to help you get started quickly and seamlessly incorporate LLMs into your agents and applications.\\nWe recommend you use LangChain if you want to quickly build agents and autonomous applications. Use LangGraph, our low-level agent orchestration framework and runtime, when you have more advanced needs that require a combination of deterministic and agentic workflows, heavy customization, and carefully controlled latency.\\nLangChain agents are built on top of LangGraph in order to provide durable execution, streaming, human-in-the-loop, persistence, and more. You do not need to know LangGraph for basic LangChain agent usage.\\n\\u200b Create an agent\\nCopy# pip install -qU langchain \"langchain[anthropic]\"\\nfrom langchain.agents import create_agent\\n\\ndef get_weather(city: str) -> str:\\n    \"\"\"Get weather for a given city.\"\"\"\\n    return f\"It\\'s always sunny in {city}!\"\\n\\nagent = create_agent(\\n    model=\"claude-sonnet-4-5-20250929\",\\n    tools=[get_weather],\\n    system_prompt=\"You are a helpful assistant\",\\n)\\n\\n# Run the agent\\nagent.invoke(\\n    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]}\\n)\\n\\nSee the Installation instructions and Quickstart guide to get started building your own agents and applications with LangChain.\\n\\u200b Core benefits\\nStandard model interfaceDifferent providers have unique APIs for interacting with models, including the format of responses. LangChain standardizes how you interact with models so that you can seamlessly swap providers and avoid lock-in.Learn moreEasy to use, highly flexible agentLangChain’s agent abstraction is designed to be easy to get started with, letting you build a simple agent in under 10 lines of code. But it also provides enough flexibility to allow you to do all the context engineering your heart desires.Learn moreBuilt on top of LangGraphLangChain’s agents are built on top of LangGraph. This allows us to take advantage of LangGraph’s durable execution, human-in-the-loop support, persistence, and more.Learn moreDebug with LangSmithGain deep visibility into complex agent behavior with visualization tools that trace execution paths, capture state transitions, and provide detailed runtime metrics.Learn more\\n\\nEdit this page on GitHub or file an issue.\\nConnect these docs to Claude, VSCode, and more via MCP for real-time answers.Was this page helpful?YesNoInstall LangChainNext⌘IDocs by LangChain home pagegithubxlinkedinyoutubeResourcesForumChangelogLangChain AcademyTrust CenterCompanyAboutCareersBloggithubxlinkedinyoutubePowered by Mintlify'),\n",
       " Document(metadata={'source': 'https://www.ibm.com/think/topics/langchain', 'title': 'What Is LangChain? | IBM', 'description': 'LangChain is an open source orchestration framework for the development of applications using large language models (LLMs), like chatbots and virtual agents.\\u202f', 'language': 'en'}, page_content='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWhat Is LangChain? | IBM\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                                   \\n\\n\\n\\n  \\n    What is LangChain?\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n                               \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAI Agents\\n\\n\\n\\nWelcome\\n\\n\\n\\n\\n\\nCaret right\\n\\nIntroduction\\n\\n\\n\\n\\nOverview\\n\\n\\n\\n\\nAI agents vs AI assistants\\n\\n\\n\\n\\n\\nCaret right\\n\\nAgentic AI\\n\\n\\n\\n\\nWhat is agentic AI?\\n\\n\\n\\n\\nWhy is agentic AI important?\\n\\n\\n\\n\\n\\n\\nAgentic AI vs generative AI\\n\\n\\n\\n\\n\\nCaret right\\n\\nAI agent development\\n\\n\\n\\n\\nWhat is AI agent development?\\n\\n\\n\\n\\nAgentOps\\n\\n\\n\\n\\nHow to build an AI agent\\n\\n\\n\\n\\n\\n\\n\\nCaret right\\n\\nTypes of AI agents\\n\\n\\n\\n\\nOverview\\n\\n\\n\\n\\nGoal-based agent\\n\\n\\n\\n\\nModel-based reflex agent\\n\\n\\n\\n\\nSimple reflex agent\\n\\n\\n\\n\\nUtility-based agent\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCaret right\\n\\nComponents\\n\\n\\n\\n\\nOverview\\n\\n\\n\\n\\n\\nCaret right\\n\\nAgentic workflows\\n\\n\\n\\n\\nWhat are agentic workflows?\\n\\n\\n\\n\\nTutorial: Agentic workflows\\n\\n\\n\\n\\n\\n\\nCommunication\\n\\n\\n\\n\\nLearning\\n\\n\\n\\n\\nMemory\\n\\n\\n\\n\\nPerception\\n\\n\\n\\n\\nPlanning\\n\\n\\n\\n\\nReasoning\\n\\n\\n\\n\\n\\nCaret right\\n\\nTool calling\\n\\n\\n\\n\\nWhat is tool calling?\\n\\n\\n\\n\\nTutorial: Ollama tool calling\\n\\n\\n\\n\\nTutorial: LM Studio tool calling\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCaret right\\n\\nArchitecture\\n\\n\\n\\n\\nOverview\\n\\n\\n\\n\\n\\nCaret right\\n\\nAI agent orchestration\\n\\n\\n\\n\\nWhat is agent orchestration?\\n\\n\\n\\n\\nTutorial: Agent orchestration\\n\\n\\n\\n\\n\\n\\nHierarchical AI agents\\n\\n\\n\\n\\n\\nCaret right\\n\\nMulti-agent systems\\n\\n\\n\\n\\nWhat are multi-agent systems?\\n\\n\\n\\n\\nTutorial: crewAI multi-agent call analysis\\n\\n\\n\\n\\n\\n\\nMulti-agent collaboration\\n\\n\\n\\n\\n\\nCaret right\\n\\nReAct\\n\\n\\n\\n\\nWhat is ReAct?\\n\\n\\n\\n\\nTutorial: LangGraph ReAct agent\\n\\n\\n\\n\\n\\n\\n\\nCaret right\\n\\nReWOO\\n\\n\\n\\n\\nWhat is ReWOO?\\n\\n\\n\\n\\nTutorial: ReWOO reasoning agent\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCaret right\\n\\nProtocols\\n\\n\\n\\n\\nOverview\\n\\n\\n\\n\\n\\nCaret right\\n\\nAgent Communication Protocol (ACP)\\n\\n\\n\\n\\nWhat is ACP?\\n\\n\\n\\n\\nTutorial: ACP agent interoperability\\n\\n\\n\\n\\n\\n\\n\\nCaret right\\n\\nAgent2Agent (A2A) protocol\\n\\n\\n\\n\\nWhat is A2A protocol?\\n\\n\\n\\n\\nTutorial: A2A chat system\\n\\n\\n\\n\\n\\n\\n\\nCaret right\\n\\nModel Context Protocol (MCP)\\n\\n\\n\\n\\nWhat is MCP?\\n\\n\\n\\n\\nTutorial: MCP server\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCaret right\\n\\nMulti-agent systems\\n\\n\\n\\n\\nOverview\\n\\n\\n\\n\\n\\nCaret right\\n\\nAgentic orchestration\\n\\n\\n\\n\\nWhat is agentic orchestration?\\n\\n\\n\\n\\nTutorial: Agent orchestration\\n\\n\\n\\n\\n\\n\\nMulti-agent collaboration\\n\\n\\n\\n\\nTutorial: crewAI multi-agent call analysis\\n\\n\\n\\n\\n\\n\\n\\nCaret right\\n\\nFrameworks\\n\\n\\n\\n\\nOverview\\n\\n\\n\\n\\n\\nCaret right\\n\\nAutoGen\\n\\n\\n\\n\\nWhat is AutoGen?\\n\\n\\n\\n\\nTutorial: AutoGen multi-agent RAG\\n\\n\\n\\n\\n\\n\\nAutoGPT\\n\\n\\n\\n\\nBabyAGI\\n\\n\\n\\n\\n\\nCaret right\\n\\nBeeAI\\n\\n\\n\\n\\nWhat is BeeAI?\\n\\n\\n\\n\\nTutorial: BeeAI agentic contract management\\n\\n\\n\\n\\n\\n\\n\\nCaret right\\n\\nChatDev\\n\\n\\n\\n\\nWhat is ChatDev?\\n\\n\\n\\n\\nTutorial: ChatDev ChatChain\\n\\n\\n\\n\\n\\n\\n\\nCaret right\\n\\ncrewAI\\n\\n\\n\\n\\nWhat is crewAI?\\n\\n\\n\\n\\nTutorial: crewAI retail shelf optimization\\n\\n\\n\\n\\n\\n\\nIBM watsonx agents\\n\\n\\n\\n\\n\\nCaret right\\n\\nLangChain\\n\\n\\n\\n\\nWhat is LangChain?\\n\\n\\n\\n\\nTutorial: LangChain agent\\n\\n\\n\\n\\n\\n\\n\\nCaret right\\n\\nLangGraph\\n\\n\\n\\n\\nWhat is LangGraph?\\n\\n\\n\\n\\nTutorial: LangGraph SQL agent\\n\\n\\n\\n\\nTutorial: LangGraph ReAct agent\\n\\n\\n\\n\\n\\n\\nLangFlow\\n\\n\\n\\n\\n\\nCaret right\\n\\nMetaGPT\\n\\n\\n\\n\\nWhat is MetaGPT?\\n\\n\\n\\n\\nTutorial: Multi-agent PRD automation\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCaret right\\n\\nGovernance\\n\\n\\n\\n\\nOverview\\n\\n\\n\\n\\nAI agent ethics\\n\\n\\n\\n\\n\\nCaret right\\n\\nAI agent evaluation\\n\\n\\n\\n\\nWhat is AI agent evaluation?\\n\\n\\n\\n\\nTutorial: AI agent evaluation\\n\\n\\n\\n\\n\\n\\nAI agent security\\n\\n\\n\\n\\n\\nCaret right\\n\\nHuman-in-the-loop\\n\\n\\n\\n\\nTutorial: Human-in-the-loop\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCaret right\\n\\nAgentic RAG\\n\\n\\n\\n\\nOverview\\n\\n\\n\\n\\nTutorial: LangChain agentic RAG \\n\\n\\n\\n\\n\\nCaret right\\n\\nAgentic chunking\\n\\n\\n\\n\\nWhat is agentic chunking?\\n\\n\\n\\n\\nTutorial: Agentic chunking for RAG\\n\\n\\n\\n\\n\\n\\n\\nCaret right\\n\\nCorrective RAG\\n\\n\\n\\n\\nTutorial: Corrective RAG\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCaret right\\n\\nUse cases / Applications\\n\\n\\n\\n\\nOverview\\n\\n\\n\\n\\nAutomation\\n\\n\\n\\n\\nCustomer service\\n\\n\\n\\n\\nFinance\\n\\n\\n\\n\\nHuman resources\\n\\n\\n\\n\\nMarketing\\n\\n\\n\\n\\nProcurement\\n\\n\\n\\n\\nSales\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        \\n\\n\\n\\n  \\n    Authors\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDave Bergmann\\n\\nSenior Staff Writer, AI Models\\nIBM Think\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCole Stryker\\n\\nStaff Editor, AI Models\\nIBM Think\\n\\n\\n\\n\\n\\n\\n\\r\\n        LangChain overview\\r\\n    \\n\\n\\n\\nLangChain is an open source orchestration framework for application development using large language models (LLMs). Available in both Python- and Javascript-based libraries, LangChain’s tools and APIs simplify the process of building LLM-driven applications like chatbots and AI agents.\\u202f\\n\\n\\nLangChain serves as a generic interface for nearly any LLM, providing a centralized development environment to build LLM applications and integrate them with external data sources and software workflows. LangChain’s module-based approach allows developers and data scientists to dynamically compare different prompts and even different foundation models with minimal need to rewrite code. This modular environment also allows for programs that use multiple LLMs: for example, an application that uses one LLM to interpret user queries and another LLM to author a response.\\nLaunched by Harrison Chase in October 2022, LangChain enjoyed a meteoric rise to prominence: as of June 2023, it was the single fastest-growing open source project on Github.1 Coinciding with the momentous launch of OpenAI’s ChatGPT the following month, LangChain has played a significant role in making generative AI\\xa0(genAI) more accessible to enthusiasts and startups in the wake of its widespread popularity. Advancements in accessibility for agentic AI are currently enabling a revolution in automation.\\nLangChain can facilitate most use cases for LLMs and natural language processing (NLP), like chatbots, intelligent search, question-answering, summarization services or even AI\\xa0agents capable of robotic process automation.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nIntegrations with LLMs\\n\\n\\nLLMs are not standalone applications: they are pre-trained statistical models that must be paired with an application (and, in some cases, specific data sources) in order to meet their purpose.\\nFor example, Chat-GPT is not an LLM: it is a chatbot application that, depending on the version you’ve chosen, uses the GPT-3.5 or GPT-4 language model. While it’s the GPT model that interprets the user’s input and composes a natural language response, it’s the application that (among other things) provides an interface for the user to type and read and a UX design that governs the chatbot experience. Even at the enterprise level, Chat-GPT is not the only application using the GPT model: Microsoft uses GPT-4 to power Bing Chat.\\nFurthermore, though foundation models (like those powering LLMs) are pre-trained on massive datasets, they are not omniscient. If a particular task requires access to specific contextual information, like internal documentation or domain expertise, LLMs must be connected to those external data sources. Even if you simply want your model to reflect real-time awareness of current events, it requires external information: a model’s internal data is only up-to-date through the time period during which it was pre-trained.\\nLikewise, if a given generative AI task requires access to external software workflows—for example, if you wanted your virtual agent to integrate with Slack—then you will need a way to integrate the LLM with the API for that software.\\nWhile these integrations can generally be achieved with fully manual code, orchestration frameworks such as LangChain and the IBM watsonx portfolio of artificial intelligence products greatly simplify the process. They also make it much easier to experiment with different LLMs to compare results, as different models can be swapped in and out with minimal changes to code.\\n\\n\\n\\r\\n        How does LangChain work?\\r\\n    \\n\\n\\n\\nAt LangChain’s core is a development environment that streamlines the programming of LLM applications through the use of\\xa0abstraction: the simplification of code by representing one or more complex processes as a named component that encapsulates all of its constituent steps.\\n\\n\\nAbstractions are a common element of everyday life and language. For example, “π” allows us to represent the ratio of the length of a circle’s circumference to that of its diameter without having to write out its infinite digits. Similarly, a thermostat allows us to control the temperature in our home without needing to understand the complex circuitry this entails—we only need to know how different thermostat settings translate to different temperatures.\\nLangChain is essentially a library of abstractions for Python and Javascript, representing common steps and concepts necessary to work with language models. These modular components—like functions and object classes—serve as the building blocks of generative AI programs. They can be “chained” together to create applications, minimizing the amount of code and fine understanding required to execute complex NLP tasks. Though LangChain’s abstracted approach may limit the extent to which an expert programmer can finely customize an application, it empowers specialists and newcomers alike to quickly experiment and prototype.\\n\\n\\nImporting language models\\n\\n\\nNearly any LLM can be used in LangChain. Importing language models into LangChain is easy, provided you have an API key. The LLM class is designed to provide a standard interface for all models.\\nMost LLM providers will require you to create an account in order to receive an API key. Some of these APIs—particularly those for proprietary closed-source models, like those offered by OpenAI or Anthropic—may have associated costs.\\nMany open source models, like Meta AI’s LLaMa, Deepseek\\'s Deepseek-LLM, IBM\\'s Granite and Google’s Flan-T5, can be accessed through Hugging Face. IBM watsonx, through its partnership with Hugging Face, also offers a curated suite of open source models. Creating an account with either service will allow you to generate an API key for any of the models offered by that provider.\\nLangChain is not limited to out-of-the-box foundation models: the CustomLLM class\\xa0allows for custom LLM wrappers. Likewise, you can use the IBM watsonx APIs and Python SDK, which includes a LangChain integration, to build applications in LangChain with models that you’ve already trained or fine-tuned for your specific needs using the WatsonxLLM class (and that model’s specific project ID).\\n\\n\\nPrompt templates\\n\\n\\nPrompts are the instructions given to an LLM. The “art” of composing prompts that effectively provide the context necessary for the LLM to interpret input and structure output in the way most useful to you is often called prompt engineering.\\nThe PromptTemplate class in LangChain formalizes the composition of prompts without the need to manually hard code context and queries. Important elements of a prompt are likewise entered as formal classes, like input_variables. A prompt template can thus contain and reproduce context, instructions (like “do not use technical terms”), a set of examples to guide its responses (in what is called “few-shot prompting”), a specified output format or a standardized question to be answered.\\u202fYou can save and name an effectively structured prompt template and easily reuse it as needed.\\nThough these elements can all be manually coded, PromptTemplate modules empower smooth integration with other LangChain features, like the eponymous chains.\\n\\n\\nChains\\n\\n\\nAs its name implies, chains are the core of LangChain’s workflows. They combine LLMs with other components, creating applications by executing a sequence of functions.\\nThe most basic chain is\\xa0LLMChain. It simply calls a model and prompt template for that model. For example, imagine you saved a prompt as “ExamplePrompt” and wanted to run it against Flan-T5. You can import LLMChain from langchain.chains, then define\\xa0chain_example = LLMChain(llm = flan-t5, prompt = ExamplePrompt). To run the chain for a given input, you simply call\\xa0chain_example.run(“input”).\\nTo use the output of one function as the input for the next function, you can use SimpleSequentialChain. Each function could utilize different prompts, different tools, different parameters or even different models, depending on your specific needs.\\n\\n\\nIndexes\\n\\n\\nTo achieve certain tasks, LLMs will need access to specific external data sources not included in its training dataset, such as internal documents, emails or datasets. LangChain collectively refers to such external documentation as “indexes”.\\n\\n\\nDocument loaders\\n\\n\\nLangChain offers\\xa0a wide variety of document loaders for third party applications. This allows for easy importation of data from sources like file storage services (like Dropbox, Google Drive and Microsoft OneDrive), web content (like YouTube, PubMed or specific URLs), collaboration tools (like Airtable, Trello, Figma and Notion), databases (like Pandas, MongoDB and Microsoft), among many others.\\n\\n\\nVector databases\\n\\n\\nUnlike “traditional” structured databases,\\xa0vector databases\\xa0represent data points by converting them into\\xa0vector embeddings: numerical representations in the form of vectors with a fixed number of dimensions, often clustering related data points using\\xa0unsupervised learning methods. This enables low latency queries, even for massive datasets, which greatly increases efficiency. Vector embeddings also store each vector’s metadata, further enhancing search possibilities.\\nLangChain provides integrations for over 25 different embedding methods, as well as for over 50 different vector stores (both cloud-hosted and local).\\n\\n\\nText splitters\\xa0\\n\\n\\nTo increase speed and reduce computational demands, it’s often wise to split large text documents into smaller pieces. LangChain’s\\xa0TextSplitters\\xa0split text up into small, semantically meaningful chunks that can then be combined using methods and parameters of your choosing.\\n\\n\\nRetrieval\\n\\n\\nOnce external sources of knowledge have been connected, the model must be able to quickly retrieve and integrate relevant information as needed. Like watsonx, LangChain offers\\xa0retrieval augmented generation (RAG):\\xa0its\\xa0retriever\\xa0modules accept a string query as an input and return a list of\\xa0Document’s as output.\\nWith LangChain, we can also build agentic RAG systems.\\xa0In traditional RAG applications, the LLM is provided with a vector database to reference when forming its responses. In contrast, agentic AI applications are not restricted to only data retrieval. Agenic RAG can also encompass tools for tasks such as solving mathematical calculations, writing emails, performing data analysis and more.\\n\\n\\nMemory\\n\\n\\nLLMs, by default, do not have any long-term memory of previous interactions (unless that chat history is used as input for a query). LangChain solves this problem with simple utilities for adding memory to a system, with options ranging from retaining the entirety of all conversations to retaining a summarization of the conversation thus far to retaining the n\\xa0most recent exchanges.\\n\\n\\nTools\\n\\n\\nDespite their heralded power and versatility, LLMs have important limitations: namely, a lack of up-to-date information, a lack of domain-specific expertise and a general difficulty with math.\\nLangChain tools\\xa0are a set of functions that empower LangChain agents to interact with real-world information in order to expand or improve the services it can provide. Examples of prominent pre-built LangChain tools include:\\n\\nWolfram Alpha: provides access to powerful computational and data visualization functions, enabling sophisticated mathematical capabilities.\\nGoogle Search: provides access to Google Search, equipping applications and agents with real-time information.\\nOpenWeatherMap: fetches weather information.\\nWikipedia: provides efficient access to information from Wikipedia articles.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nIndustry newsletter\\n\\n\\n\\nThe latest AI trends, brought to you by experts\\n\\n\\n\\nGet curated insights on the most important—and intriguing—AI news. Subscribe to our weekly Think newsletter. See the IBM Privacy Statement.\\n\\n\\n\\n\\nThank you! You are subscribed.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nYour subscription will be delivered in English. You will find an unsubscribe link in every newsletter. You can manage your subscriptions or unsubscribe here. Refer to our IBM Privacy Statement for more information.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\r\\n        LangChain agents\\r\\n    \\n\\n\\n\\nWe can build an\\xa0agent\\xa0with the LangChain framework to give an LLM the ability to make decisions, use tools and complete complex tasks step-by-step, rather than just generating a single text response. Unlike a simple prompt-response interaction with just an LLM, an agent powered by LangChain can think, plan, execute a sequence of actions, learn and adapt.\\nLangChain provides a streamlined user experience with a ready-made, extensible framework for creating AI agents, so there’s no need to build new tool selection logic, reasoning loops (such as for ReAct agents), observation/action tracking or prompt orchestration and formatting.\\nThe specific LangChain packages, classes and methods vary depending on the AI platform you intend to use. Some key components of the WatsonxLLM class that allow for communication with watsonx.ai models using LangChain include:\\nlangchain_ibm: The package responsible for the LangChain IBM integration. It is necessary to install this package to use any of the following classes and methods.ibm_watsonx_ai: The library that allows connection to watsonx.ai services like IBM Cloud and IBM Cloud Pak for Data.APIClient: The main class of the ibm_watsonx_ai\\xa0library that manages the API service resources. The parameters include the API credentials and endpoint.WatsonxLLM: The wrapper for IBM watsonx.ai foundation models. This wrapper provides chain integration and is necessary to import. The parameters include the model ID, watsonx.ai API key, URL endpoint, project ID as well as any LLM parameters.ModelInference: The class that instantiates the model interface. The parameters include the model ID, watsonx.ai credentials, project ID, model parameters and more. Once instantiated, the model can then be passed into the class.invoke: The method that calls the model directly with a single prompt of string type.\\xa0generate:\\xa0The method that calls the model with multiple prompts of string type in a list.\\nAnother LangChain class for building AI agents with the integration of tool calling and chaining with\\xa0watsonx.ai models is ChatWatsonx. This class, which is leveraged in many of our tutorials, uses the bind_tools method to pass a list of tools to the LLM upon each iteration. These can include both custom and pre-built tools. To retrieve the AI agent response, the invoke method\\xa0can be used. Once the agent is invoked, the tool_calls attribute\\xa0of the response displays the name, arguments, id and type of each tool call made, if any.\\n\\n\\nLangGraph\\n\\n\\nLangGraph, created by LangChain,\\xa0is an open source AI agent framework that supports multi-agent orchestration and enables developers to build\\xa0agentic workflows\\xa0where different agents interact, specialize and collaborate.\\xa0\\nAt its core, LangGraph uses the power of graph-based architectures to model and manage the intricate relationships between various components of an\\xa0AI agent workflow.\\xa0Combined with the human-in-the-loop monitoring mechanism and a set of API and tool integrations, LangGraph provides users with a versatile platform for developing AI solutions and workflows including\\xa0chatbots, state graphs and\\xa0other agent-based systems.\\xa0\\nWith the langchain-mcp-adapters library, LangGraph agents can also use tools defined on model context protocol (MCP) servers. The mcp library allows users to build custom MCP servers as well. Essentially, MCP enables a secure connection between an AI system, such as an AI agent, and external tools. Thus, various LLMs can connect to the same tools and data sources given the standard MCP.\\xa0\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n  \\n      AI agents\\n  \\n\\n\\n\\n\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            \\n\\n\\n\\n  \\n    5 Types of AI Agents: Autonomous Functions & Real-World Applications\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n        \\n\\n\\nLearn how goal-driven and utility-based AI adapt to workflows and complex environments.\\n\\n\\n\\n\\n\\n\\nBuild, deploy and monitor AI agents\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\r\\n        LangSmith\\r\\n    \\n\\n\\n\\nReleased in the fall of 2023, LangSmith aims to bridge the gap between the accessible prototyping capabilities that brought LangChain to prominence and building production-quality LLM applications.\\xa0\\nLangSmith provides tools to monitor, evaluate and debug applications, including the ability to automatically trace all model calls to spot errors and test performance under different model configurations. The use of LangSmith is not limited to applications built using the LangChain ecosystem. The evaluation of agent performance is done using LLM-as-a-judge evaluators. This observability\\xa0and these key metrics aim to optimize more robust, cost-efficient applications.\\xa0\\n\\n\\n\\n\\n\\n\\r\\n        Getting started with LangChain\\r\\n    \\n\\n\\n\\nLangChain is open source and free to use: source code is\\xa0available for download on Github.\\nLangChain can also be installed on Python with a simple pip command: pip install langchain. To install all LangChain dependencies (rather than only those you find necessary), you can run the command\\xa0pip install langchain[all].\\nMany step-by-step tutorials are provided by IBM including LangChain tool calling, agentic RAG, LLM agent orchestration,\\xa0agentic chunking and more.\\n\\n\\n\\r\\n        LangChain use cases\\r\\n    \\n\\n\\n\\nAI Applications made with LangChain provide great utility for a variety of use cases, from straightforward question-answering and text generation tasks to more complex solutions that use an LLM as a “reasoning engine.”\\n\\n\\nChatbots\\n\\n\\nChatbots are among the most intuitive uses of LLMs. LangChain can be used to provide proper context for the specific use of a chatbot, and to integrate chatbots into existing communication channels and workflows with their own APIs.\\n\\n\\nSummarization\\n\\n\\nLanguage models can be tasked with summarizing many types of text, from breaking down complex academic articles and transcripts to providing a digest of incoming emails.\\n\\n\\nQuestion answering\\n\\n\\nUsing specific documents or specialized knowledge bases (like Wolfram, arXiv or PubMed), LLMs can retrieve relevant information from storage and articulate helpful answers). If fine-tuned or properly prompted, some LLMs can answer many questions even without external information.\\n\\n\\nData augmentation\\n\\n\\nLLMs can be used to generate\\xa0synthetic data\\xa0for use in\\xa0machine learning. For example, an LLM can be trained to generate additional data samples that closely resemble the data points in a training dataset.\\n\\n\\nVirtual agents\\n\\n\\nIntegrated with the right workflows, LangChain’s Agent modules can use an LLM to autonomously determine next steps and take action using robotic process automation (RPA).\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                Link copied\\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                Ebook\\n            \\n\\n                Start realizing ROI: A practical guide to agentic AI \\n            \\nDiscover ways to get ahead, successfully scaling AI across your business with real results.\\n\\nRead the ebook\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nBuild, run and manage AI agents with watsonx Orchestrate\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            \\n\\n\\n\\n  \\n    Resources\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                Report\\n            \\n\\n                AI governance imperative: evolving regulations and emergence of agentic AI\\n            \\nLearn how evolving regulations and the emergence of AI agents are reshaping the need for robust AI governance frameworks.\\n\\nRead the report\\n\\n\\n\\n\\n\\n\\n\\n\\n                Report\\n            \\n\\n                IDC MarketScape names IBM a Leader in 2025 GenAI evaluation technology\\n            \\nDownload the report to learn why IDC MarketScape names IBM a Leader in 2025 GenAI evaluation technology, and how watsonx.governance advances risk management, reporting, and integration.\\n\\nRead the report\\n\\n\\n\\n\\n\\n\\n\\n\\n                2025 AI Agents buyer\\'s guide\\n            \\n\\n                How AI agents and assistants can benefit your organization\\n            \\nDive into this comprehensive guide that breaks down key use cases, core capabilities, and step-by-step recommendations to help you choose the right solutions for your business.\\n\\nRead the guide\\n\\n\\n\\n\\n\\n\\n\\n\\n                Video\\n            \\n\\n                Reimagine business productivity with AI agents and assistants\\n            \\nLearn how AI agents and AI assistants can work together to achieve new levels of productivity.\\n\\nWatch now\\n\\n\\n\\n\\n\\n\\n\\n\\n                Demo\\n            \\n\\n                Try watsonx Orchestrate™\\n            \\nExplore how generative AI assistants can lighten your workload and improve productivity.\\n\\nStart the demo\\n\\n\\n\\n\\n\\n\\n\\n\\n                Report\\n            \\n\\n                From AI projects to profits: How agentic AI can sustain financial returns\\n            \\nLearn how organizations are shifting from launching AI in disparate pilots to using it to drive transformation at the core.\\r\\n\\n\\nRead the report\\n\\n\\n\\n\\n\\n\\n\\n\\n                Report\\n            \\n\\n                Omdia Report on empowered intelligence: The impact of AI agents\\n            \\nDiscover how you can unlock the full potential of gen AI with AI agents.\\r\\n\\n\\nRead the report\\n\\n\\n\\n\\n\\n\\n\\n\\n                Podcast\\n            \\n\\n                How AI agents will reinvent productivity\\n            \\nLearn ways to use AI to be more creative, efficient and start adapting to a future that involves working closely with AI agents.\\n\\nListen now\\n\\n\\n\\n\\n\\n\\n\\n\\n                News\\n            \\n\\n                Ushering in the agentic enterprise: Putting AI to work across your entire technology estate\\n            \\nStay updated about the new emerging AI agents, a fundamental tipping point in the AI revolution.\\n\\nRead the news\\n\\n\\n\\n\\n\\n\\n\\n\\n                Podcast\\n            \\n\\n                The future of agents, AI energy consumption, Anthropic\\'s computer use and Google watermarking AI-generated text\\n            \\nStay ahead of the curve with our AI experts on this episode of Mixture of Experts as they dive deep into the future of AI agents and more.\\r\\n\\n\\nListen now\\n\\n\\n\\n\\n\\n\\n\\n\\n                Case study\\n            \\n\\n                How Comparus is using a \"banking assistant\"\\n            \\nComparus used solutions from IBM® watsonx.ai™ and impressively demonstrated the potential of conversational banking as a new interaction model.\\n\\nRead the case study\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        \\n        \\n\\n     \\n    Related solutions\\n\\n\\n\\n\\n    \\n\\n\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        \\n\\n\\n\\n  \\n    IBM®\\xa0watsonx\\xa0Orchestrate™\\xa0\\n\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n    \\n\\n\\n\\nEasily design scalable AI assistants and agents, automate repetitive tasks and simplify complex processes with\\xa0IBM®\\xa0watsonx\\xa0Orchestrate™.\\n\\n\\n\\n\\nExplore watsonx Orchestrate\\n                \\n                \\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        \\n\\n\\n\\n  \\n    Artificial intelligence solutions\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n    \\n\\n\\n\\nPut AI to work in your business with IBM\\'s industry-leading AI expertise and portfolio of solutions at your side.\\n\\n\\n\\n\\nExplore AI solutions\\n                \\n                \\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        \\n\\n\\n\\n  \\n    AI consulting and services\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n    \\n\\n\\n\\nReinvent critical workflows and operations by adding AI to maximize experiences, real-time decision-making and business value.\\n\\n\\n\\n\\nExplore AI services\\n                \\n                \\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTake the next step\\n\\n\\n\\n\\nWhether you choose to customize pre-built apps and skills or build and deploy custom agentic services using an AI studio, the IBM watsonx platform has you covered.\\n\\n\\n\\n\\n\\n\\nExplore watsonx Orchestrate\\n\\n\\n\\n\\nExplore watsonx.ai\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'),\n",
       " Document(metadata={'source': 'https://en.wikipedia.org/wiki/LangChain', 'title': 'LangChain - Wikipedia', 'language': 'en'}, page_content='\\n\\n\\n\\nLangChain - Wikipedia\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to content\\n\\n\\n\\n\\n\\n\\n\\nMain menu\\n\\n\\n\\n\\n\\nMain menu\\nmove to sidebar\\nhide\\n\\n\\n\\n\\t\\tNavigation\\n\\t\\n\\n\\nMain pageContentsCurrent eventsRandom articleAbout WikipediaContact us\\n\\n\\n\\n\\n\\n\\t\\tContribute\\n\\t\\n\\n\\nHelpLearn to editCommunity portalRecent changesUpload fileSpecial pages\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAppearance\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDonate\\n\\nCreate account\\n\\nLog in\\n\\n\\n\\n\\n\\n\\n\\n\\nPersonal tools\\n\\n\\n\\n\\n\\nDonate Create account Log in\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nContents\\nmove to sidebar\\nhide\\n\\n\\n\\n\\n(Top)\\n\\n\\n\\n\\n\\n1\\nHistory\\n\\n\\n\\n\\n\\n\\n\\n\\n2\\nCapabilities\\n\\n\\n\\n\\n\\n\\n\\n\\n3\\nLangChain tools\\n\\n\\n\\n\\n\\n\\n\\n\\n4\\nReferences\\n\\n\\n\\n\\n\\n\\n\\n\\n5\\nExternal links\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nToggle the table of contents\\n\\n\\n\\n\\n\\n\\n\\nLangChain\\n\\n\\n\\n12 languages\\n\\n\\n\\n\\nCatalàفارسی한국어हिन्दी日本語PortuguêsРусскийSimple EnglishไทยTürkçeУкраїнська中文\\n\\nEdit links\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nArticleTalk\\n\\n\\n\\n\\n\\nEnglish\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nReadEditView history\\n\\n\\n\\n\\n\\n\\n\\nTools\\n\\n\\n\\n\\n\\nTools\\nmove to sidebar\\nhide\\n\\n\\n\\n\\t\\tActions\\n\\t\\n\\n\\nReadEditView history\\n\\n\\n\\n\\n\\n\\t\\tGeneral\\n\\t\\n\\n\\nWhat links hereRelated changesUpload filePermanent linkPage informationCite this pageGet shortened URLDownload QR code\\n\\n\\n\\n\\n\\n\\t\\tPrint/export\\n\\t\\n\\n\\nDownload as PDFPrintable version\\n\\n\\n\\n\\n\\n\\t\\tIn other projects\\n\\t\\n\\n\\nWikimedia CommonsWikidata item\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAppearance\\nmove to sidebar\\nhide\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFrom Wikipedia, the free encyclopedia\\n\\n\\n\\nLanguage model application development framework\\nLangChainDeveloperHarrison ChaseInitial releaseOctober 2022Stable release0.1.16[1]\\n   / 11 April 2024; 20 months ago\\xa0(11 April 2024)\\nRepositorygithub.com/langchain-ai/langchainWritten inPython and JavaScriptTypeSoftware framework for large language model application developmentLicenseMIT LicenseWebsiteLangChain.com\\n\\nFree and open-source software portal\\nLangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain\\'s use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.[2]\\n\\n\\nHistory[edit]\\nLangChain was launched in October 2022 as an open source project by Harrison Chase, while working at machine learning startup Robust Intelligence. In April 2023, LangChain had incorporated and the new startup raised over $20 million in funding at a valuation of at least $200 million from venture firm Sequoia Capital, a week after announcing a $10 million seed investment from Benchmark.[3][4]\\nIn the third quarter of 2023, the LangChain Expression Language (LCEL) was introduced, which provides a declarative way to define chains of actions.[5][6]\\nIn October 2023 LangChain introduced LangServe, a deployment tool to host LCEL code as a production-ready API.[7]\\nIn February 2024 LangChain released LangSmith, a closed-source observability and evaluation platform for LLM applications, and announced a US $25 million Series A led by Sequoia Capital.[8] On 14 May 2025 the company launched LangGraph Platform into general availability, providing managed infrastructure for deploying long-running, stateful AI agents.[9]\\n\\nCapabilities[edit]\\nLangChain\\'s developers highlight the framework\\'s applicability to use-cases including chatbots,[10] retrieval-augmented generation,[11]  document summarization,[12] and synthetic data generation.[13]\\nAs of March 2023, LangChain included integrations with systems including Amazon, Google, and Microsoft Azure cloud storage;[14] API wrappers for news, movie information, and weather; Bash for summarization, syntax and semantics checking, and execution of shell scripts; multiple web scraping subsystems and templates; few-shot learning prompt generation support; finding and summarizing \"todo\" tasks in code; Google Drive documents, spreadsheets, and presentations summarization, extraction, and creation; Google Search and Microsoft Bing web search;[15] OpenAI, Anthropic, and Hugging Face language models; iFixit repair guides and wikis search and summarization; MapReduce for question answering, combining documents, and question generation; N-gram overlap scoring; PyPDF, pdfminer, fitz, and pymupdf for PDF file text extraction and manipulation; Python and JavaScript code generation, analysis, and debugging; Milvus vector database[16] to store and retrieve vector embeddings; Weaviate vector database[17] to cache embedding and data objects; Redis cache database storage; Python RequestsWrapper and other methods for API requests; SQL and NoSQL databases including JSON support; Streamlit, including for logging; text mapping for k-nearest neighbors search; time zone conversion and calendar operations; tracing and recording stack symbols in threaded and asynchronous subprocess runs; and the Wolfram Alpha website and SDK.[18] As of April 2023, it can read from more than 50 document types and data sources.[19]\\n\\nLangChain tools[edit]\\n\\n\\n\\n\\nTool name\\n\\nAccount required?\\n\\nAPI key required?\\n\\nLicencing\\n\\nFeatures\\n\\nDocumentation URL\\n\\n\\nAlpha  Vantage\\n\\nNo\\n\\nYes\\n\\nProprietary\\n\\nFinancial data, analytics\\n\\nhttps://python.langchain.com/docs/integrations/tools/alpha_vantage\\n\\n\\nApify\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nWeb scraping, automation\\n\\nhttps://python.langchain.com/docs/integrations/providers/apify/\\n\\n\\nArXiv\\n\\nNo\\n\\nNo\\n\\nOpen  Source\\n\\nScientific  papers, research\\n\\nhttps://python.langchain.com/docs/integrations/tools/arxiv\\n\\n\\nAWS  Lambda\\n\\nYes\\n\\nYes\\n\\nProprietary\\n\\nServerless  computing\\n\\nhttps://python.langchain.com/docs/integrations/tools/awslambda\\n\\n\\nBash\\n\\nNo\\n\\nNo\\n\\nOpen  source\\n\\nShell environment access\\n\\nhttps://python.langchain.com/docs/integrations/tools/bash\\n\\n\\nBearly Code Interpreter\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nRemote Python code execution\\n\\nhttps://python.langchain.com/docs/integrations/tools/bearly\\n\\n\\nBing Search\\n\\nNo\\n\\nYes\\n\\nProprietary\\n\\nSearch engine\\n\\nhttps://python.langchain.com/docs/integrations/tools/bing_search\\n\\n\\nBrave Search\\n\\nNo\\n\\nNo\\n\\nOpen  source\\n\\nPrivacy-focused  search\\n\\nhttps://python.langchain.com/docs/integrations/tools/brave_search\\n\\n\\nChatGPT Plugins\\n\\nNo\\n\\nYes\\n\\nProprietary\\n\\nChatGPT\\n\\nhttps://python.langchain.com/docs/integrations/tools/chatgpt_plugins\\n\\n\\nConnery\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nAPI actions\\n\\nhttps://python.langchain.com/docs/integrations/tools/connery\\n\\n\\nDall-E Image Generator\\n\\nNo\\n\\nYes\\n\\nProprietary\\n\\nText-to-image  generation\\n\\nhttps://python.langchain.com/docs/integrations/tools/dalle_image_generator\\n\\n\\nDataForSEO\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nSEO data, analytics\\n\\nhttps://python.langchain.com/docs/integrations/tools/dataforseo\\n\\n\\nDuckDuckGo  Search\\n\\nNo\\n\\nNo\\n\\nOpen  source\\n\\nPrivacy-focused search\\n\\nhttps://python.langchain.com/docs/integrations/tools/ddg\\n\\n\\nE2B Data Analysis\\n\\nNo\\n\\nNo\\n\\nOpen  source\\n\\nData analysis\\n\\nhttps://python.langchain.com/docs/integrations/tools/e2b_data_analysis\\n\\n\\nEden AI\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nAI tools, APIs\\n\\nhttps://python.langchain.com/docs/integrations/tools/edenai_tools\\n\\n\\nEleven Labs Text2Speech\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nText-to-speech\\n\\nhttps://python.langchain.com/docs/integrations/tools/eleven_labs_tts\\n\\n\\nExa Search\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nWeb search\\n\\nhttps://python.langchain.com/docs/integrations/tools/exa_search\\n\\n\\nFile System\\n\\nNo\\n\\nNo\\n\\nOpen  source\\n\\nFile system interaction\\n\\nhttps://python.langchain.com/docs/integrations/tools/filesystem\\n\\n\\nGolden Query\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nNatural  language queries\\n\\nhttps://python.langchain.com/docs/integrations/tools/golden_query\\n\\n\\nGoogle Cloud Text-to-Speech\\n\\nYes\\n\\nYes\\n\\nProprietary\\n\\nText-to-speech\\n\\nhttps://python.langchain.com/docs/integrations/tools/google_cloud_texttospeech\\n\\n\\nGoogle Drive\\n\\nYes\\n\\nYes\\n\\nProprietary\\n\\nGoogle Drive access\\n\\nhttps://python.langchain.com/docs/integrations/tools/google_drive\\n\\n\\nGoogle Finance\\n\\nYes\\n\\nYes\\n\\nProprietary\\n\\nFinancial data\\n\\nhttps://python.langchain.com/docs/integrations/tools/google_finance\\n\\n\\nGoogle Jobs\\n\\nYes\\n\\nYes\\n\\nProprietary\\n\\nJob search\\n\\nhttps://python.langchain.com/docs/integrations/tools/google_jobs\\n\\n\\nGoogle Lens\\n\\nYes\\n\\nYes\\n\\nProprietary\\n\\nVisual  search, recognition\\n\\nhttps://python.langchain.com/docs/integrations/tools/google_lens\\n\\n\\nGoogle Places\\n\\nYes\\n\\nYes\\n\\nProprietary\\n\\nLocation-based  services\\n\\nhttps://python.langchain.com/docs/integrations/tools/google_places\\n\\n\\nGoogle Scholar\\n\\nYes\\n\\nYes\\n\\nProprietary\\n\\nScholarly  article search\\n\\nhttps://python.langchain.com/docs/integrations/tools/google_scholar\\n\\n\\nGoogle Search\\n\\nYes\\n\\nYes\\n\\nProprietary\\n\\nSearch engine\\n\\nhttps://python.langchain.com/docs/integrations/tools/google_search\\n\\n\\nGoogle Serper\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nSERP scraping\\n\\nhttps://python.langchain.com/docs/integrations/tools/google_serper\\n\\n\\nGoogle Trends\\n\\nYes\\n\\nYes\\n\\nProprietary\\n\\nTrend data\\n\\nhttps://python.langchain.com/docs/integrations/tools/google_trends\\n\\n\\nGradio\\n\\nNo\\n\\nNo\\n\\nOpen  source\\n\\nMachine learning UIs\\n\\nhttps://python.langchain.com/docs/integrations/tools/gradio_tools\\n\\n\\nGraphQL\\n\\nNo\\n\\nNo\\n\\nOpen  source\\n\\nAPI queries\\n\\nhttps://python.langchain.com/docs/integrations/tools/graphql\\n\\n\\nHuggingFace  Hub\\n\\nNo\\n\\nNo\\n\\nOpen  source\\n\\nHugging Face models, datasets\\n\\nhttps://python.langchain.com/docs/integrations/tools/huggingface_tools\\n\\n\\nHuman as a tool\\n\\nNo\\n\\nNo\\n\\nN/A\\n\\nHuman input\\n\\nhttps://python.langchain.com/docs/integrations/tools/human_tools\\n\\n\\nIFTTT WebHooks\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nWeb service automation\\n\\nhttps://python.langchain.com/docs/integrations/tools/ifttt\\n\\n\\nIonic Shopping\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nShopping\\n\\nhttps://python.langchain.com/docs/integrations/tools/ionic_shopping\\n\\n\\nLemon Agent\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nLemon AI interaction\\n\\nhttps://python.langchain.com/docs/integrations/tools/lemonai\\n\\n\\nMemorize\\n\\nNo\\n\\nNo\\n\\nOpen  source\\n\\nFine-tune LLM to memorize information using unsupervised learning\\n\\nhttps://python.langchain.com/docs/integrations/tools/memorize\\n\\n\\nNuclia\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nIndexing of unstructured data\\n\\nhttps://python.langchain.com/docs/integrations/tools/nuclia\\n\\n\\nOpenWeatherMap\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nWeather data\\n\\nhttps://python.langchain.com/docs/integrations/tools/openweathermap\\n\\n\\nPolygon Stock Market API\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nStock market data\\n\\nhttps://python.langchain.com/docs/integrations/tools/polygon\\n\\n\\nPubMed\\n\\nNo\\n\\nNo\\n\\nOpen  source\\n\\nBiomedical  literature\\n\\nhttps://python.langchain.com/docs/integrations/tools/pubmed\\n\\n\\nPython REPL\\n\\nNo\\n\\nNo\\n\\nOpen  source\\n\\nPython shell\\n\\nhttps://python.langchain.com/docs/integrations/tools/python\\n\\n\\nReddit Search\\n\\nNo\\n\\nNo\\n\\nOpen  source\\n\\nReddit search\\n\\nhttps://python.langchain.com/docs/integrations/tools/reddit_search\\n\\n\\nRequests\\n\\nNo\\n\\nNo\\n\\nOpen  source\\n\\nHTTP requests\\n\\nhttps://python.langchain.com/docs/integrations/tools/requests\\n\\n\\nSceneXplain\\n\\nNo\\n\\nNo\\n\\nOpen  source\\n\\nModel explanations\\n\\nhttps://python.langchain.com/docs/integrations/tools/sceneXplain\\n\\n\\nSearch\\n\\nNo\\n\\nNo\\n\\nOpen  source\\n\\nQuery various search services\\n\\nhttps://python.langchain.com/docs/integrations/tools/search_tools\\n\\n\\nSearchApi\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nQuery various search services\\n\\nhttps://python.langchain.com/docs/integrations/tools/searchapi\\n\\n\\nSearxNG\\n\\nNo\\n\\nNo\\n\\nOpen  source\\n\\nPrivacy-focused  search\\n\\nhttps://python.langchain.com/docs/integrations/tools/searx_search\\n\\n\\nSemantic Scholar API\\n\\nNo\\n\\nNo\\n\\nOpen  source\\n\\nAcademic  paper search\\n\\nhttps://python.langchain.com/docs/integrations/tools/semanticscholar\\n\\n\\nSerpAPI\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nSearch engine results page scraping\\n\\nhttps://python.langchain.com/docs/integrations/tools/serpapi\\n\\n\\nStackExchange\\n\\nNo\\n\\nNo\\n\\nOpen  source\\n\\nStack  Exchange access\\n\\nhttps://python.langchain.com/docs/integrations/tools/stackexchange\\n\\n\\nTavily Search\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nQuestion  answering\\n\\nhttps://python.langchain.com/docs/integrations/tools/tavily_search\\n\\n\\nTwilio\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nCommunication  APIs\\n\\nhttps://python.langchain.com/docs/integrations/tools/twilio\\n\\n\\nWikidata\\n\\nNo\\n\\nNo\\n\\nOpen  source\\n\\nStructured  data access\\n\\nhttps://python.langchain.com/docs/integrations/tools/wikidata\\n\\n\\nWikipedia\\n\\nNo\\n\\nNo\\n\\nOpen  source\\n\\nWikipedia  access\\n\\nhttps://python.langchain.com/docs/integrations/tools/wikipedia\\n\\n\\nWolfram Alpha\\n\\nNo\\n\\nYes\\n\\nProprietary\\n\\nComputational  knowledge\\n\\nhttps://python.langchain.com/docs/integrations/tools/wolfram_alpha\\n\\n\\nYahoo Finance News\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nFinancial news\\n\\nhttps://python.langchain.com/docs/integrations/tools/yahoo_finance_news\\n\\n\\nYoutube\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nYouTube  access\\n\\nhttps://python.langchain.com/docs/integrations/tools/youtube\\n\\n\\nZapier Natural Language Actions\\n\\nNo\\n\\nYes\\n\\nCommercial\\n\\nWorkflow  automation\\n\\nhttps://python.langchain.com/docs/integrations/tools/zapier\\n\\nReferences[edit]\\n\\n\\n^ \"Release 0.1.16\". 11 April 2024. Retrieved 23 April 2024.\\n\\n^ Buniatyan, Davit (2023). \"Code Understanding Using LangChain\". Activeloop.\\n\\n^ Palazzolo, Stephanie (2023-04-13). \"AI startup LangChain taps Sequoia to lead funding round at a valuation of at least $200 million\". Business Insider. Archived from the original on 2023-04-18. Retrieved 2023-04-18.\\n\\n^ Griffith, Erin; Metz, Cade (2023-03-14). \"\\'Let 1,000 Flowers Bloom\\': A.I. Funding Frenzy Escalates\". The New York Times. ISSN\\xa00362-4331. Archived from the original on 2023-04-18. Retrieved 2023-04-18.\\n\\n^ Mansurova, Mariya (2023-10-30). \"Topic Modelling in production: Leveraging LangChain to move from ad-hoc Jupyter Notebooks to production modular service\". towardsdatascience.com. Retrieved 2024-07-08.\\n\\n^ \"LangChain Expression Language\". langchain.dev. 2023-08-01. Retrieved 2024-07-08.\\n\\n^ \"Introducing LangServe, the best way to deploy your LangChains\". LangChain Blog. 2023-10-12. Retrieved 2023-10-17.\\n\\n^ \"Announcing the General Availability of LangSmith and Our Series A Led By Sequoia Capital\". LangChain Blog. 2024-02-15. Retrieved 2025-08-03.\\n\\n^ \"LangGraph Platform is now Generally Available: Deploy & manage long-running, stateful Agents\". LangChain Blog. 2025-05-14. Retrieved 2025-08-03.\\n\\n^ \"Chatbots | 🦜️🔗 Langchain\". python.langchain.com. Archived from the original on 2024-03-14. Retrieved 2023-11-26.\\n\\n^ \"Retrieval-augmented generation (RAG) | 🦜️🔗 Langchain\". python.langchain.com. Archived from the original on 2024-03-28. Retrieved 2023-11-26.\\n\\n^ \"Summarization | 🦜️🔗 Langchain\". python.langchain.com. Archived from the original on 2024-01-06. Retrieved 2023-11-26.\\n\\n^ \"Synthetic data generation | 🦜️🔗 Langchain\". python.langchain.com. Archived from the original on 2024-03-07. Retrieved 2023-11-26.\\n\\n^ \"Azure Cognitive Search and LangChain: A Seamless Integration for Enhanced Vector Search Capabilities\". TECHCOMMUNITY.MICROSOFT.COM. Retrieved 2024-08-31.\\n\\n^ \"Best Alternative AI Content Strategies and LLM Frameworks\". Medium. 2024-08-31. Retrieved 2024-08-31.\\n\\n^ \"Milvus — LangChain\". python.langchain.com. Retrieved 2023-10-29.\\n\\n^ \"Weaviate\". python.langchain.com. Retrieved 2024-01-17.\\n\\n^ Hug, Daniel Patrick (2023-03-08). \"Hierarchical topic tree of LangChain\\'s integrations\" (PDF). GitHub. Archived from the original on 2023-04-29. Retrieved 2023-04-18.\\n\\n^ \"Document Loaders — LangChain 0.0.142\". python.langchain.com. Archived from the original on 2023-04-18. Retrieved 2023-04-18.\\n\\n\\nExternal links[edit]\\n\\n\\nLangChain  at Wikipedia\\'s sister projects\\n\\nMedia from CommonsData from Wikidata\\n\\nOfficial website\\nLangchain-ai on GitHub\\nvteOpenAIProductsChatGPT\\nAtlas\\nDALL-E\\nDeep Research\\nGPT Image\\nGPT Store\\nSearch\\nSora\\nWhisper\\nFoundationmodels\\nOpenAI Codex\\nGenerative pre-trained transformer\\nGPT-1\\nGPT-2\\nGPT-3\\nGPT-4\\nGPT-4o\\no1\\no3\\nGPT-4.5\\nGPT-4.1\\no4-mini\\nGPT-OSS\\nGPT-5\\nGPT-5.1\\nGPT-5.2\\nIntelligentagents\\nOperator\\nPeopleSeniormanagementCurrent\\nSam Altman\\nremoval\\nGreg Brockman\\nSarah Friar\\nJakub Pachocki\\nScott Schools\\nFormer\\nMira Murati\\nEmmett Shear\\nBoard ofdirectorsCurrent\\nSam Altman\\nAdam D\\'Angelo\\nSue Desmond-Hellmann\\nZico Kolter\\nPaul Nakasone\\nAdebayo Ogunlesi\\nNicole Seligman\\nFidji Simo\\nBret Taylor (chair)\\nFormer\\nGreg Brockman (2017–2023)\\nReid Hoffman (2019–2023)\\nWill Hurd (2021–2023)\\nHolden Karnofsky (2017–2021)\\nElon Musk (2015–2018)\\nIlya Sutskever (2017–2023)\\nHelen Toner (2021–2023)\\nShivon Zilis (2019–2023)\\nLawrence Summers (2023-2025)\\nJVs\\nStargate LLC\\nRelated\\nChatGPT in education\\nApple Intelligence\\nAI Dungeon\\nAutoGPT\\nGitHub Copilot\\nContrastive Language-Image Pre-training\\n\"Deep Learning\"\\nLangChain\\nMicrosoft Copilot\\nOpenAI Five\\nTransformer\\n\\n Category\\n\\nvteDifferentiable computingGeneral\\nDifferentiable programming\\nInformation geometry\\nStatistical manifold\\nAutomatic differentiation\\nNeuromorphic computing\\nPattern recognition\\nRicci calculus\\nComputational learning theory\\nInductive bias\\nHardware\\nIPU\\nTPU\\nVPU\\nMemristor\\nSpiNNaker\\nSoftware libraries\\nTensorFlow\\nPyTorch\\nKeras\\nscikit-learn\\nTheano\\nJAX\\nFlux.jl\\nMindSpore\\n\\n Portals\\nComputer programming\\nTechnology\\n\\n\\n\\n\\n\\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=LangChain&oldid=1324784520\"\\nCategories: AI softwareLarge language modelsSoftware frameworks2022 softwareHidden categories: Articles with short descriptionShort description matches WikidataPages using Sister project links with hidden wikidata\\n\\n\\n\\n\\n\\n\\n This page was last edited on 29 November 2025, at 15:38\\xa0(UTC).\\nText is available under the Creative Commons Attribution-ShareAlike 4.0 License;\\nadditional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization.\\n\\n\\nPrivacy policy\\nAbout Wikipedia\\nDisclaimers\\nContact Wikipedia\\nCode of Conduct\\nDevelopers\\nStatistics\\nCookie statement\\nMobile view\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nToggle the table of contents\\n\\n\\n\\n\\n\\n\\n\\nLangChain\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n12 languages\\n\\n\\nAdd topic\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = [\n",
    "    \"https://www.geeksforgeeks.org/artificial-intelligence/introduction-to-langchain/\",\n",
    "    \"https://docs.langchain.com/oss/python/langchain/overview\",\n",
    "    \"https://www.ibm.com/think/topics/langchain\",\n",
    "    \"https://en.wikipedia.org/wiki/LangChain\"\n",
    "]\n",
    "\n",
    "loader = WebBaseLoader(web_paths=urls)\n",
    "final_loader = loader.load()\n",
    "final_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee27549c",
   "metadata": {},
   "source": [
    "### Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1f571e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://www.geeksforgeeks.org/artificial-intelligence/introduction-to-langchain/', 'title': 'Introduction to LangChain - GeeksforGeeks', 'description': 'Your All-in-One Learning Portal: GeeksforGeeks is a comprehensive educational platform that empowers learners across domains-spanning computer science and programming, school education, upskilling, commerce, software tools, competitive exams, and more.', 'language': 'en-US'}, page_content='Introduction to LangChain - GeeksforGeeks\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to content'),\n",
       " Document(metadata={'source': 'https://www.geeksforgeeks.org/artificial-intelligence/introduction-to-langchain/', 'title': 'Introduction to LangChain - GeeksforGeeks', 'description': 'Your All-in-One Learning Portal: GeeksforGeeks is a comprehensive educational platform that empowers learners across domains-spanning computer science and programming, school education, upskilling, commerce, software tools, competitive exams, and more.', 'language': 'en-US'}, page_content='Skip to content\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCoursesDSA / PlacementsGATE PrepML & Data ScienceDevelopmentCloud / DevOpsProgramming LanguagesAll CoursesTutorialsPythonJavaDSAML & Data ScienceInterview CornerProgramming LanguagesWeb DevelopmentGATECS SubjectsDevOpsSchool LearningSoftware and ToolsPracticePractice Coding ProblemsNation Skillup- Ending Soon!Problem of the DayAI Agent Workshop (with Certification)Study Abroad ChampionshipJobsApply Now!Post JobsJobs UpdatesApply for Campus Mantri')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap=150)\n",
    "final_split2 = splitter.split_documents(final_loader)\n",
    "final_split2[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2579c651",
   "metadata": {},
   "source": [
    "#### Converting the Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e1e22b",
   "metadata": {},
   "source": [
    "### Store in Chroma DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "007c0767",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddinds2 = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "text_list2 = [doc.page_content for doc in final_split2]\n",
    "vector = embeddinds2.embed_documents(text_list2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ecee4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Store into Vector DB\n",
    "store2 = FAISS.from_documents(documents=final_split2,embedding=embeddinds2)\n",
    "store2.save_local(\"./basha_langchain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6176f545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='9a083043-c685-4b2e-95aa-2d29184c3f04', metadata={'source': 'https://www.ibm.com/think/topics/langchain', 'title': 'What Is LangChain? | IBM', 'description': 'LangChain is an open source orchestration framework for the development of applications using large language models (LLMs), like chatbots and virtual agents.\\u202f', 'language': 'en'}, page_content='Getting started with LangChain'),\n",
       " Document(id='207ce6c9-18b7-4a2b-b4dc-c778f80a31cf', metadata={'source': 'https://www.ibm.com/think/topics/langchain', 'title': 'What Is LangChain? | IBM', 'description': 'LangChain is an open source orchestration framework for the development of applications using large language models (LLMs), like chatbots and virtual agents.\\u202f', 'language': 'en'}, page_content='How does LangChain work?\\r\\n    \\n\\n\\n\\nAt LangChain’s core is a development environment that streamlines the programming of LLM applications through the use of\\xa0abstraction: the simplification of code by representing one or more complex processes as a named component that encapsulates all of its constituent steps.'),\n",
       " Document(id='75e9608d-1606-459c-96d9-869ac1f20fc7', metadata={'source': 'https://en.wikipedia.org/wiki/LangChain', 'title': 'LangChain - Wikipedia', 'language': 'en'}, page_content='^ \"Milvus — LangChain\". python.langchain.com. Retrieved 2023-10-29.\\n\\n^ \"Weaviate\". python.langchain.com. Retrieved 2024-01-17.\\n\\n^ Hug, Daniel Patrick (2023-03-08). \"Hierarchical topic tree of LangChain\\'s integrations\" (PDF). GitHub. Archived from the original on 2023-04-29. Retrieved 2023-04-18.\\n\\n^ \"Document Loaders — LangChain 0.0.142\". python.langchain.com. Archived from the original on 2023-04-18. Retrieved 2023-04-18.\\n\\n\\nExternal links[edit]\\n\\n\\nLangChain  at Wikipedia\\'s sister projects'),\n",
       " Document(id='50f3dbbc-e84b-49f2-9c3d-9d4a6401f5ff', metadata={'source': 'https://www.ibm.com/think/topics/langchain', 'title': 'What Is LangChain? | IBM', 'description': 'LangChain is an open source orchestration framework for the development of applications using large language models (LLMs), like chatbots and virtual agents.\\u202f', 'language': 'en'}, page_content='LangChain is open source and free to use: source code is\\xa0available for download on Github.\\nLangChain can also be installed on Python with a simple pip command: pip install langchain. To install all LangChain dependencies (rather than only those you find necessary), you can run the command\\xa0pip install langchain[all].\\nMany step-by-step tutorials are provided by IBM including LangChain tool calling, agentic RAG, LLM agent orchestration,\\xa0agentic chunking and more.')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store2.similarity_search(\"What is LangChain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bb0bcbcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredTool(name='retrive data from store2 db ', description='Search and run information about Langchain', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=<function create_retriever_tool.<locals>.func at 0x000001B28719E980>, coroutine=<function create_retriever_tool.<locals>.afunc at 0x000001B28719FB00>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.tools import create_retriever_tool\n",
    "\n",
    "langchian_retrieval_tool = create_retriever_tool(\n",
    "    retrieval,\n",
    "    \"retrive data from store2 db \",\n",
    "    \"Search and run information about Langchain\"\n",
    "    \n",
    ")\n",
    "langchian_retrieval_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "64ca133c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StructuredTool(name='retrive data from store db ', description='Search and run information about LangGraph', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=<function create_retriever_tool.<locals>.func at 0x000001B28719D8A0>, coroutine=<function create_retriever_tool.<locals>.afunc at 0x000001B28719C540>),\n",
       " StructuredTool(name='retrive data from store2 db ', description='Search and run information about Langchain', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=<function create_retriever_tool.<locals>.func at 0x000001B28719E980>, coroutine=<function create_retriever_tool.<locals>.afunc at 0x000001B28719FB00>)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Combine All the tools\n",
    "tools = [langGraph_retrieval_tool,langchian_retrieval_tool]\n",
    "\n",
    "tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef4b9e9",
   "metadata": {},
   "source": [
    "#### Create a LangGraph Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa90e6b",
   "metadata": {},
   "source": [
    "#### Create a State Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e5822d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated,Sequence,Literal\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import add_messages\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages:Annotated[Sequence[BaseMessage],add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ac5d8798",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent(state:AgentState):\n",
    "    \"\"\"\n",
    "    Invokes the agent model to generate a response based on the current state. \n",
    "    Given the question, it will decide to retrive using the retriever tool.\n",
    "    \n",
    "    Args:\n",
    "        state (messages): The Current State\n",
    "    \n",
    "    Returns:\n",
    "        dict:The updated state with the agent response appended to messages\n",
    "    \"\"\"\n",
    "    print(\"---CALL AGENT---\")\n",
    "    messages = state[\"messages\"]\n",
    "    model = ChatGroq(model=\"llama-3.1-8b-instant\")\n",
    "    model = model.bind_tools(tools)\n",
    "    response = model.invoke(messages)\n",
    "    return {\"messages\":[response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b298601d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain import hub\n",
    "from langchain_core.messages import BaseMessage,HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "\n",
    "def grade_documents(state:AgentState)->Literal[\"generate\",\"rewrite\"]:\n",
    "    \"\"\"\n",
    "    Determine whether the retrieved documents are relevant to the question.\n",
    "    \n",
    "    Args:  \n",
    "        state(messages): The current state\n",
    "        \n",
    "    Returns:\n",
    "        str: A decision for whether the documents are relevant or not\n",
    "    \n",
    "    \"\"\"\n",
    "    print(\"---CHECK RELEVACE\")\n",
    "    \n",
    "    #Data model\n",
    "    class grade(BaseModel):\n",
    "        \"\"\"Binary score for relevance check\"\"\"\n",
    "        \n",
    "        binary_score :str = Field(description=\"Relevance score 'yes' or 'no' \")\n",
    "        \n",
    "    #LLM\n",
    "    model = ChatGroq(model=\"llama-3.1-8b-instant\")\n",
    "    llm_with_tool = model.with_structured_output(grade)\n",
    "    \n",
    "    #Prompt\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"You are grader assessing velevance of a retrieved document to a user question.\\n\n",
    "        Here is the retrieved document: \\n\\n {context}\\n\\n\n",
    "        Here is the user question: {question} \\n\n",
    "        If the document contains keyword(s) or semantic meaning related to the user question, grade\n",
    "        it as relevant.\\n \n",
    "        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question\"\"\",\n",
    "        input_variables=[\"context\",\"question\"],\n",
    "    )\n",
    "    \n",
    "    #Chain\n",
    "    chain = prompt|llm_with_tool\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    question = messages[0].content\n",
    "    context = last_message.content\n",
    "    \n",
    "    scored_result = chain.invoke({\"question\":question,\"context\":context})\n",
    "    \n",
    "    score = scored_result.binary_score\n",
    "    \n",
    "    if score == \"yes\":\n",
    "        print(\"---DECISION DOCS RELEVENT---\")\n",
    "        return \"generate\"\n",
    "    else:\n",
    "        print(\"---DECISION DOES NOT RELEVANT\")\n",
    "        print(score)\n",
    "        return \"rewrite\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df10ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from click import prompt\n",
    "\n",
    "\n",
    "def generate(state:AgentState):\n",
    "    \"\"\"\n",
    "    Generate answer\n",
    "    \n",
    "    Args:\n",
    "        state(messages):The Current State\n",
    "    \n",
    "    Returns:\n",
    "        dict: The Update Message\n",
    "    \n",
    "    \"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "    last_message = messages[-1]\n",
    "    context = last_message.content\n",
    "    \n",
    "    #Prompt\n",
    "    hub.pull(\"rlm/rag-prompt\")\n",
    "    \n",
    "    #LLM\n",
    "    model = ChatGroq(model=\"llama-3.1-8b-instant\")\n",
    "    \n",
    "    #Post Processing\n",
    "    def formate_docs(context):\n",
    "        return \"\\n\\n\".join(context.page_content for contexts in context )\n",
    "    \n",
    "    #Chain\n",
    "    rag_chain = prompt|model|StrOutputParser()\n",
    "    \n",
    "    #Run\n",
    "    response = rag_chain.invoke({\"context\":context , \"question\":question })\n",
    "    return {\"messages\":[response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c690b455",
   "metadata": {},
   "source": [
    "## Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "43bf44ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rewrite' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m retrieve = ToolNode(tools)      \u001b[38;5;66;03m#Retrieval\u001b[39;00m\n\u001b[32m      9\u001b[39m graph.add_node(\u001b[33m\"\u001b[39m\u001b[33mretrieve\u001b[39m\u001b[33m\"\u001b[39m,retrieve)  \u001b[38;5;66;03m#ReWriting the Question\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m graph.add_node(\u001b[33m\"\u001b[39m\u001b[33mrewrite\u001b[39m\u001b[33m\"\u001b[39m,\u001b[43mrewrite\u001b[49m)\n\u001b[32m     11\u001b[39m graph.add_node(\n\u001b[32m     12\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mgenerate\u001b[39m\u001b[33m\"\u001b[39m,generate\n\u001b[32m     13\u001b[39m )\u001b[38;5;66;03m#Generating a response after we know the documents are relevant \u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m#Call agent node to decide to retrieval or not\u001b[39;00m\n\u001b[32m     15\u001b[39m \n\u001b[32m     16\u001b[39m \n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Add Edges\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'rewrite' is not defined"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph,START,END\n",
    "from langgraph.prebuilt import ToolNode,tools_condition\n",
    "\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "## Add Nodes\n",
    "graph.add_node(\"agent\",agent)  #Agent Node\n",
    "retrieve = ToolNode(tools)      #Retrieval\n",
    "graph.add_node(\"retrieve\",retrieve)  #ReWriting the Question\n",
    "graph.add_node(\"rewrite\",rewrite)\n",
    "graph.add_node(\n",
    "    \"generate\",generate\n",
    ")#Generating a response after we know the documents are relevant \n",
    "#Call agent node to decide to retrieval or not\n",
    "\n",
    "\n",
    "# Add Edges\n",
    "graph.add_edge(START,\"agent\")\n",
    "graph.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    tools_condition,\n",
    "    {\n",
    "        \"tools\":\"retrieve\",\n",
    "        END:END\n",
    "    },\n",
    ")\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"retrieve\",\n",
    "    grade_documents,\n",
    ")\n",
    "\n",
    "#Compile Graph\n",
    "graph_builder = graph.complie()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "241a2dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- CALL AGENT ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\LangGraphSeries\\module01\\venv\\Lib\\site-packages\\pydantic\\main.py:250: UserWarning: WARNING! tool_choice is not default parameter.\n",
      "                    tool_choice was transferred to model_kwargs.\n",
      "                    Please confirm that tool_choice is what you intended.\n",
      "  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- FINAL ANSWER ---\n",
      "content=\"Agentic RAG is a framework used in Agile project management to track the status of tasks or user stories. RAG stands for Red, Amber, and Green, which are colors used to represent the status of the task. \\n\\n- Green (G): Indicates that the task is done or completed.\\n- Amber (A): Suggests that the task is partially done, but it still needs work.\\n- Red (R): Signifies that the task has stalled or has significant issues.\\n\\nThis framework is 'Agentic' because it is used by the team to make decisions and prioritize tasks based on their status. It helps team members to stay aware of where they are with their tasks and makes it easier to manage their workload and adjust the project timeline if necessary.\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 154, 'prompt_tokens': 69, 'total_tokens': 223, 'completion_time': 0.400650854, 'completion_tokens_details': None, 'prompt_time': 0.004578499, 'prompt_tokens_details': None, 'queue_time': 0.056063871, 'total_time': 0.405229353}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4387d3edbb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'} id='lc_run--019b310d-93eb-7df0-aa03-0ecaceeb8e56-0' usage_metadata={'input_tokens': 69, 'output_tokens': 154, 'total_tokens': 223}\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Imports\n",
    "# ===============================\n",
    "from typing import Annotated, Sequence, Literal\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# Retriever Tool\n",
    "# ===============================\n",
    "def retrieve_documents(query: str) -> str:\n",
    "    \"\"\"Simple retriever tool\"\"\"\n",
    "    return f\"Agentic RAG is an advanced form of RAG where agents reason, decide, and iterate using tools.\"\n",
    "\n",
    "\n",
    "tools = [retrieve_documents]\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# Agent State\n",
    "# ===============================\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# Agent Node (FIXED)\n",
    "# ===============================\n",
    "def agent(state: AgentState):\n",
    "    print(\"\\n--- CALL AGENT ---\")\n",
    "\n",
    "    model = ChatGroq(\n",
    "        model=\"llama-3.1-8b-instant\",\n",
    "        tool_choice=\"none\"   # 🔥 prevents brave_search error\n",
    "    ).bind_tools(tools)\n",
    "\n",
    "    response = model.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# Relevance Grader\n",
    "# ===============================\n",
    "def grade_documents(state: AgentState) -> Literal[\"generate\", \"rewrite\"]:\n",
    "    print(\"\\n--- CHECK RELEVANCE ---\")\n",
    "\n",
    "    class Grade(BaseModel):\n",
    "        binary_score: str = Field(description=\"yes or no\")\n",
    "\n",
    "    model = ChatGroq(model=\"llama-3.1-8b-instant\")\n",
    "    llm = model.with_structured_output(Grade)\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"\n",
    "Check if the document is relevant to the question.\n",
    "\n",
    "Document:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer only yes or no.\n",
    "\"\"\",\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "    )\n",
    "\n",
    "    chain = prompt | llm\n",
    "\n",
    "    question = state[\"messages\"][0].content\n",
    "    context = state[\"messages\"][-1].content\n",
    "\n",
    "    result = chain.invoke({\"question\": question, \"context\": context})\n",
    "\n",
    "    return \"generate\" if result.binary_score == \"yes\" else \"rewrite\"\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# Rewrite Node\n",
    "# ===============================\n",
    "def rewrite(state: AgentState):\n",
    "    print(\"\\n--- REWRITE QUESTION ---\")\n",
    "\n",
    "    model = ChatGroq(model=\"llama-3.1-8b-instant\")\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"Rewrite the question for better retrieval:\\n{question}\",\n",
    "        input_variables=[\"question\"],\n",
    "    )\n",
    "\n",
    "    chain = prompt | model | StrOutputParser()\n",
    "\n",
    "    question = state[\"messages\"][0].content\n",
    "    rewritten = chain.invoke({\"question\": question})\n",
    "\n",
    "    return {\"messages\": [HumanMessage(content=rewritten)]}\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# Generate Node\n",
    "# ===============================\n",
    "def generate(state: AgentState):\n",
    "    print(\"\\n--- GENERATE ANSWER ---\")\n",
    "\n",
    "    model = ChatGroq(model=\"llama-3.1-8b-instant\")\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"\n",
    "Use the context to answer the question.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\",\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "    )\n",
    "\n",
    "    chain = prompt | model | StrOutputParser()\n",
    "\n",
    "    question = state[\"messages\"][0].content\n",
    "    context = state[\"messages\"][-1].content\n",
    "\n",
    "    answer = chain.invoke({\"context\": context, \"question\": question})\n",
    "    return {\"messages\": [answer]}\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# Build LangGraph\n",
    "# ===============================\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"agent\", agent)\n",
    "graph.add_node(\"retrieve\", ToolNode(tools))\n",
    "graph.add_node(\"rewrite\", rewrite)\n",
    "graph.add_node(\"generate\", generate)\n",
    "\n",
    "graph.add_edge(START, \"agent\")\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    tools_condition,\n",
    "    {\n",
    "        \"tools\": \"retrieve\",\n",
    "        END: END\n",
    "    },\n",
    ")\n",
    "\n",
    "graph.add_conditional_edges(\"retrieve\", grade_documents)\n",
    "\n",
    "graph.add_edge(\"rewrite\", \"agent\")\n",
    "graph.add_edge(\"generate\", END)\n",
    "\n",
    "graph_builder = graph.compile()\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# Run\n",
    "# ===============================\n",
    "if __name__ == \"__main__\":\n",
    "    result = graph_builder.invoke(\n",
    "        {\"messages\": [HumanMessage(content=\"What is Agentic RAG?\")]}\n",
    "    )\n",
    "\n",
    "    print(\"\\n--- FINAL ANSWER ---\")\n",
    "    print(result[\"messages\"][-1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
