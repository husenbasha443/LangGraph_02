{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78a42083",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model=\"llama-3.1-8b-instant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39cd8f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<function __main__.add(a: int, b: int) -> int>,\n",
       " <function __main__.divide(a: int, b: int) -> int>,\n",
       " <function __main__.multiply(a: int, b: int) -> int>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def multiply(a:int,b:int)->int:\n",
    "    \"\"\"Muultiply a and b\n",
    "\n",
    "    Args:\n",
    "        a (int): First int\n",
    "        b (int): Second int\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    return a*b\n",
    "\n",
    "def add(a:int,b:int)->int:\n",
    "    \"\"\"Addition of a and b\n",
    "\n",
    "    Args:\n",
    "        a (int): First int\n",
    "        b (int): Second int\n",
    "\n",
    "   \n",
    "    \"\"\"\n",
    "    return a+b\n",
    "\n",
    "def divide(a:int,b:int)->int:\n",
    "    \"\"\"Divide a and b\n",
    "\n",
    "    Args:\n",
    "        a (int): First int\n",
    "        b (int): Second int\n",
    "   \n",
    "    \"\"\"\n",
    "    return a/b\n",
    "\n",
    "tools = [add,divide,multiply]  \n",
    "tools  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e0d7902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I\\'m unable to provide a definition for \"ai\" as it can refer to various things such as Artificial Intelligence, American Idol, etc. If you could provide more context, I can try to provide a more accurate answer.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 46, 'prompt_tokens': 361, 'total_tokens': 407, 'completion_time': 0.080091106, 'completion_tokens_details': None, 'prompt_time': 0.019953873, 'prompt_tokens_details': None, 'queue_time': 0.050188496, 'total_time': 0.100044979}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4387d3edbb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b2bbc-e592-7b02-8c32-f25aa935468f-0', usage_metadata={'input_tokens': 361, 'output_tokens': 46, 'total_tokens': 407})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##First Way to pass as a List\n",
    "llm_with_tools = model.bind_tools([add,divide,multiply])\n",
    "llm_with_tools\n",
    "\n",
    "llm_with_tools.invoke(\"What is ai\")\n",
    "\n",
    "\n",
    "##Another way\n",
    "#llm_with_tools = model.bind_tools(tools)\n",
    "#tools\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b1f4aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage,AIMessage\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "\n",
    "st_msg = AIMessage(content=\"you are helpful to provide the assistance of arthmetic operations\")\n",
    "\n",
    "def assistance(state:MessagesState):\n",
    "    return {\"messages\":[llm_with_tools.invoke([st_msg] + state[\"messages\"])]}\n",
    "\n",
    "def human_feedback(state:MessagesState):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1e6303",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to reach https://mermaid.ink API while trying to render your graph. Status code: 400.\n\nTo resolve this issue:\n1. Check your internet connection and try again\n2. Try with higher retry settings: `draw_mermaid_png(..., max_retries=5, retry_delay=2.0)`\n3. Use the Pyppeteer rendering method which will render your graph locally in a browser: `draw_mermaid_png(..., draw_method=MermaidDrawMethod.PYPPETEER)`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     25\u001b[39m graph.add_edge(\u001b[33m\"\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mhuman_feedback\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     27\u001b[39m graph_builder = graph.compile(interrupt_before=[\u001b[33m'\u001b[39m\u001b[33mhuman_feedback\u001b[39m\u001b[33m'\u001b[39m],checkpointer=memory)\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m display(Image(\u001b[43mgraph_builder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw_mermaid_png\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\LangGraphSeries\\module01\\venv\\Lib\\site-packages\\langchain_core\\runnables\\graph.py:693\u001b[39m, in \u001b[36mGraph.draw_mermaid_png\u001b[39m\u001b[34m(self, curve_style, node_colors, wrap_label_n_words, output_file_path, draw_method, background_color, padding, max_retries, retry_delay, frontmatter_config, base_url, proxies)\u001b[39m\n\u001b[32m    683\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrunnables\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph_mermaid\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: PLC0415\u001b[39;00m\n\u001b[32m    684\u001b[39m     draw_mermaid_png,\n\u001b[32m    685\u001b[39m )\n\u001b[32m    687\u001b[39m mermaid_syntax = \u001b[38;5;28mself\u001b[39m.draw_mermaid(\n\u001b[32m    688\u001b[39m     curve_style=curve_style,\n\u001b[32m    689\u001b[39m     node_colors=node_colors,\n\u001b[32m    690\u001b[39m     wrap_label_n_words=wrap_label_n_words,\n\u001b[32m    691\u001b[39m     frontmatter_config=frontmatter_config,\n\u001b[32m    692\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m693\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw_mermaid_png\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdraw_method\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdraw_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\LangGraphSeries\\module01\\venv\\Lib\\site-packages\\langchain_core\\runnables\\graph_mermaid.py:312\u001b[39m, in \u001b[36mdraw_mermaid_png\u001b[39m\u001b[34m(mermaid_syntax, output_file_path, draw_method, background_color, padding, max_retries, retry_delay, base_url, proxies)\u001b[39m\n\u001b[32m    306\u001b[39m     img_bytes = asyncio.run(\n\u001b[32m    307\u001b[39m         _render_mermaid_using_pyppeteer(\n\u001b[32m    308\u001b[39m             mermaid_syntax, output_file_path, background_color, padding\n\u001b[32m    309\u001b[39m         )\n\u001b[32m    310\u001b[39m     )\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m draw_method == MermaidDrawMethod.API:\n\u001b[32m--> \u001b[39m\u001b[32m312\u001b[39m     img_bytes = \u001b[43m_render_mermaid_using_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    322\u001b[39m     supported_methods = \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join([m.value \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m MermaidDrawMethod])\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\LangGraphSeries\\module01\\venv\\Lib\\site-packages\\langchain_core\\runnables\\graph_mermaid.py:475\u001b[39m, in \u001b[36m_render_mermaid_using_api\u001b[39m\u001b[34m(mermaid_syntax, output_file_path, background_color, file_type, max_retries, retry_delay, proxies, base_url)\u001b[39m\n\u001b[32m    470\u001b[39m     \u001b[38;5;66;03m# For other status codes, fail immediately\u001b[39;00m\n\u001b[32m    471\u001b[39m     msg = (\n\u001b[32m    472\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to reach \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m API while trying to render \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    473\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33myour graph. Status code: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    474\u001b[39m     ) + error_msg_suffix\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m    477\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (requests.RequestException, requests.Timeout) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attempt < max_retries:\n\u001b[32m    479\u001b[39m         \u001b[38;5;66;03m# Exponential backoff with jitter\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: Failed to reach https://mermaid.ink API while trying to render your graph. Status code: 400.\n\nTo resolve this issue:\n1. Check your internet connection and try again\n2. Try with higher retry settings: `draw_mermaid_png(..., max_retries=5, retry_delay=2.0)`\n3. Use the Pyppeteer rendering method which will render your graph locally in a browser: `draw_mermaid_png(..., draw_method=MermaidDrawMethod.PYPPETEER)`"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import START,END,StateGraph\n",
    "from IPython.display import Image,display,SVG\n",
    "from langgraph.prebuilt import ToolNode,tools_condition\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "###Define the Graph\n",
    "graph = StateGraph(MessagesState)\n",
    "\n",
    "## Define the Nodes\n",
    "graph.add_node(\"human_feedback\",human_feedback)\n",
    "graph.add_node(\"tools\",ToolNode(tools))\n",
    "graph.add_node(\"assistance\",assistance)\n",
    "\n",
    "## Define the Edges\n",
    "graph.add_edge(START,\"human_feedback\")\n",
    "graph.add_edge(\"human_feedback\",\"assistance\")\n",
    "graph.add_conditional_edges(\n",
    "    \"assistance\",\n",
    "    tools_condition,\n",
    "    \n",
    ")\n",
    "graph.add_edge(\"tools\",\"human_feedback\")\n",
    "\n",
    "graph_builder = graph.compile(interrupt_before=['human_feedback'],checkpointer=memory)\n",
    "\n",
    "display(Image(graph_builder.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aecb84b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "config:\n",
      "  flowchart:\n",
      "    curve: linear\n",
      "---\n",
      "graph TD;\n",
      "\t__start__([<p>__start__</p>]):::first\n",
      "\thuman_feedback(human_feedback<hr/><small><em>__interrupt = before</em></small>)\n",
      "\ttools(tools)\n",
      "\tassistance(assistance)\n",
      "\t__end__([<p>__end__</p>]):::last\n",
      "\t__start__ --> human_feedback;\n",
      "\tassistance -.-> __end__;\n",
      "\tassistance -.-> tools;\n",
      "\thuman_feedback --> assistance;\n",
      "\ttools --> human_feedback;\n",
      "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
      "\tclassDef first fill-opacity:0\n",
      "\tclassDef last fill:#bfb6fc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(graph_builder.get_graph().draw_mermaid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6da8708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 1. Load environment variables\n",
    "# ===============================\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# ===============================\n",
    "# 2. Fix Jupyter asyncio issue\n",
    "# ===============================\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# ===============================\n",
    "# 3. Create LLM\n",
    "# ===============================\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model = ChatGroq(\n",
    "    model=\"llama-3.1-8b-instant\"\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "# 4. Define tools\n",
    "# ===============================\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Addition\"\"\"\n",
    "    return a + b\n",
    "\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplication\"\"\"\n",
    "    return a * b\n",
    "\n",
    "def divide(a: int, b: int) -> float:\n",
    "    \"\"\"Division\"\"\"\n",
    "    return a / b\n",
    "\n",
    "tools = [add, multiply, divide]\n",
    "\n",
    "llm_with_tools = model.bind_tools(tools)\n",
    "\n",
    "# ===============================\n",
    "# 5. LangGraph imports\n",
    "# ===============================\n",
    "from langchain_core.messages import AIMessage\n",
    "from langgraph.graph import StateGraph, START\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# ===============================\n",
    "# 6. Define nodes\n",
    "# ===============================\n",
    "system_msg = AIMessage(\n",
    "    content=\"You are a helpful assistant for arithmetic operations.\"\n",
    ")\n",
    "\n",
    "def assistant(state: MessagesState):\n",
    "    response = llm_with_tools.invoke(\n",
    "        [system_msg] + state[\"messages\"]\n",
    "    )\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def human_feedback(state: MessagesState):\n",
    "    # Human-in-the-loop interrupt\n",
    "    pass\n",
    "\n",
    "# ===============================\n",
    "# 7. Build graph\n",
    "# ===============================\n",
    "memory = MemorySaver()\n",
    "graph = StateGraph(MessagesState)\n",
    "\n",
    "graph.add_node(\"human_feedback\", human_feedback)\n",
    "graph.add_node(\"assistant\", assistant)\n",
    "graph.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "graph.add_edge(START, \"human_feedback\")\n",
    "graph.add_edge(\"human_feedback\", \"assistant\")\n",
    "graph.add_conditional_edges(\"assistant\", tools_condition)\n",
    "graph.add_edge(\"tools\", \"human_feedback\")\n",
    "\n",
    "graph_builder = graph.compile(\n",
    "    interrupt_before=[\"human_feedback\"],\n",
    "    checkpointer=memory\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "# 8. Draw Mermaid graph (Jupyter-safe)\n",
    "# ===============================\n",
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "\n",
    "display(\n",
    "    Image(\n",
    "        graph_builder.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.PYPPETEER\n",
    "        )\n",
    "    )\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
