{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1dafda32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model=\"llama-3.1-8b-instant\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e8c7c4",
   "metadata": {},
   "source": [
    "#### Create a Custom Tools "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a5fcc06d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<function __main__.add(a: int, b: int) -> int>,\n",
       " <function __main__.divide(a: int, b: int) -> int>,\n",
       " <function __main__.multiply(a: int, b: int) -> int>]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def multiply(a:int,b:int)->int:\n",
    "    \"\"\"Muultiply a and b\n",
    "\n",
    "    Args:\n",
    "        a (int): First int\n",
    "        b (int): Second int\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    return a*b\n",
    "\n",
    "def add(a:int,b:int)->int:\n",
    "    \"\"\"Addition of a and b\n",
    "\n",
    "    Args:\n",
    "        a (int): First int\n",
    "        b (int): Second int\n",
    "\n",
    "   \n",
    "    \"\"\"\n",
    "    return a+b\n",
    "\n",
    "def divide(a:int,b:int)->int:\n",
    "    \"\"\"Divide a and b\n",
    "\n",
    "    Args:\n",
    "        a (int): First int\n",
    "        b (int): Second int\n",
    "   \n",
    "    \"\"\"\n",
    "    return a/b\n",
    "\n",
    "tools = [add,divide,multiply]  \n",
    "tools  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ae3cc9",
   "metadata": {},
   "source": [
    "### Integrate LLM with Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "096ec798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm not sure I understand your question. Can you provide more context or clarify what you are looking for? If you are looking for information on artificial intelligence, I can suggest calling the function 'brave_search' to get more information. \\n\\nHowever, if you are referring to 'ai' as in the function 'add' where a=1 and b=0, I can provide you with the following:\\n\\n\", additional_kwargs={'tool_calls': [{'id': 'm40heya71', 'function': {'arguments': '{\"a\":1,\"b\":0}', 'name': 'add'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 101, 'prompt_tokens': 361, 'total_tokens': 462, 'completion_time': 0.17871665, 'completion_tokens_details': None, 'prompt_time': 0.02005087, 'prompt_tokens_details': None, 'queue_time': 0.055133049, 'total_time': 0.19876752}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4387d3edbb', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b2b8a-8dfd-7962-bac3-a2cabefbd769-0', tool_calls=[{'name': 'add', 'args': {'a': 1, 'b': 0}, 'id': 'm40heya71', 'type': 'tool_call'}], usage_metadata={'input_tokens': 361, 'output_tokens': 101, 'total_tokens': 462})"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##First Way to pass as a List\n",
    "llm_with_tools = model.bind_tools([add,divide,multiply])\n",
    "llm_with_tools\n",
    "\n",
    "llm_with_tools.invoke(\"What is ai\")\n",
    "\n",
    "\n",
    "##Another way\n",
    "#llm_with_tools = model.bind_tools(tools)\n",
    "#tools\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243c3475",
   "metadata": {},
   "source": [
    "#### create a State"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d376b68c",
   "metadata": {},
   "source": [
    "#### Create a Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e1b50344",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage,AIMessage\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "\n",
    "st_msg = AIMessage(content=\"you are helpful to provide the assistance of arthmetic operations\")\n",
    "\n",
    "def assistance(state:MessagesState):\n",
    "    return {\"messages\":[llm_with_tools.invoke([st_msg] + state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4ba8eb05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langgraph.graph import START,END,StateGraph\n",
    "from IPython.display import Image,display\n",
    "from langgraph.prebuilt import ToolNode,tools_condition\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "###Define the Graph\n",
    "graph = StateGraph(MessagesState)\n",
    "\n",
    "##Define the nodes\n",
    "graph.add_node(\"assistance\",assistance)\n",
    "graph.add_node(\"tools\",ToolNode(tools))\n",
    "\n",
    "##Define the edges\n",
    "graph.add_edge(START,\"assistance\")\n",
    "graph.add_conditional_edges(\n",
    "    \"assistance\",\n",
    "    tools_condition,\n",
    "    ## If the msg from assistance is a tool call->tools_condition routes the tools\n",
    "    ## If the msg  from assistance is not a tool call -< tools_conditions routes to END\n",
    "  \n",
    ")\n",
    "graph.add_edge(\"tools\",\"assistance\")\n",
    "\n",
    "## Add Human Feedback and Memory CheckPointer\n",
    "graph_builder = graph.compile(interrupt_before=[\"assistance\"],checkpointer=memory)\n",
    "\n",
    "display(Image(graph_builder.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c69e039",
   "metadata": {},
   "source": [
    "#### Create a Memory Thread "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "add0e16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"configurable\":\n",
    "        {\"thread_id\":\"111\"}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fa7d6e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Divide 10 and 2\n"
     ]
    }
   ],
   "source": [
    "### Create a Human Message\n",
    "from pprint import pprint\n",
    "message = {\"messages\":HumanMessage(content=\"Divide 10 and 2\")}\n",
    "\n",
    "for event in graph_builder.stream(message,config,stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fa25baed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('assistance',)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## To see which state is to be exucute next \n",
    "state = graph_builder.get_state(config)\n",
    "state.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "217f3780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='Divide 10 and 2', additional_kwargs={}, response_metadata={}, id='5eef2400-09e3-4e0e-b89d-bc1988f10e3d'), HumanMessage(content='Plz add 15 and 25', additional_kwargs={}, response_metadata={}, id='ce318b9c-ab57-4a1f-b0e0-f440b5613fea'), HumanMessage(content='Divide 10 and 2', additional_kwargs={}, response_metadata={}, id='fc82de2c-3b7d-48fb-bdb3-182e17ad0a27'), HumanMessage(content='Plz add 15 and 25', additional_kwargs={}, response_metadata={}, id='9dfe1c05-4e7f-4d92-b4cc-2a437a4863b9'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '4gcyf591g', 'function': {'arguments': '{\"a\":10,\"b\":2}', 'name': 'divide'}, 'type': 'function'}, {'id': 'xbr2jmftb', 'function': {'arguments': '{\"a\":15,\"b\":25}', 'name': 'add'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 420, 'total_tokens': 456, 'completion_time': 0.05022321, 'completion_tokens_details': None, 'prompt_time': 0.041250216, 'prompt_tokens_details': None, 'queue_time': 0.050364904, 'total_time': 0.091473426}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4387d3edbb', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b2abb-dcbd-75b0-bc5e-03735a7aa460-0', tool_calls=[{'name': 'divide', 'args': {'a': 10, 'b': 2}, 'id': '4gcyf591g', 'type': 'tool_call'}, {'name': 'add', 'args': {'a': 15, 'b': 25}, 'id': 'xbr2jmftb', 'type': 'tool_call'}], usage_metadata={'input_tokens': 420, 'output_tokens': 36, 'total_tokens': 456}), ToolMessage(content='5.0', name='divide', id='4e76713b-f6e8-426f-b640-9f3dcece6a67', tool_call_id='4gcyf591g'), ToolMessage(content='40', name='add', id='525f9717-ca66-46c6-b5a5-a3444b59a2e7', tool_call_id='xbr2jmftb'), HumanMessage(content='Plz Multiply 200 and 110', additional_kwargs={}, response_metadata={}, id='c1b2520b-8bf1-4ff2-8c1d-6ac80845924e'), HumanMessage(content='Plz Multiply 200 and 110', additional_kwargs={}, response_metadata={}, id='3f15980a-36ee-4f99-b03b-afbd6fea02b5'), HumanMessage(content='Plz Multiply 200 and 110', additional_kwargs={}, response_metadata={}, id='fab5c5e9-51ac-49a5-86dc-ca74c99508c2'), HumanMessage(content='Plz Multiply 200 and 110', additional_kwargs={}, response_metadata={}, id='68407802-5733-4a85-a5fa-b5a24afe8b80'), HumanMessage(content='Plz Multiply 200 and 110', additional_kwargs={}, response_metadata={}, id='50f0aec9-1a83-48c1-b01c-38b1742001c9'), HumanMessage(content='Divide 10 and 2', additional_kwargs={}, response_metadata={}, id='23850f07-3c21-47e3-a8f6-4ad9ee47c7a3'), HumanMessage(content='Plz add 15 and 25', additional_kwargs={}, response_metadata={}, id='9dcc77fa-c2aa-45a8-8eb1-160bb545f6a1'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'zfrrbqcpe', 'function': {'arguments': '{\"a\":200,\"b\":110}', 'name': 'multiply'}, 'type': 'function'}, {'id': '4trym1z5j', 'function': {'arguments': '{\"a\":200,\"b\":110}', 'name': 'multiply'}, 'type': 'function'}, {'id': 'k70xbdkyr', 'function': {'arguments': '{\"a\":200,\"b\":110}', 'name': 'multiply'}, 'type': 'function'}, {'id': '6xvkwvjfw', 'function': {'arguments': '{\"a\":200,\"b\":110}', 'name': 'multiply'}, 'type': 'function'}, {'id': '1jbmjdnpp', 'function': {'arguments': '{\"a\":200,\"b\":110}', 'name': 'multiply'}, 'type': 'function'}, {'id': 'p1gm791n6', 'function': {'arguments': '{\"a\":10,\"b\":2}', 'name': 'divide'}, 'type': 'function'}, {'id': 'c05jc43th', 'function': {'arguments': '{\"a\":15,\"b\":25}', 'name': 'add'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 126, 'prompt_tokens': 566, 'total_tokens': 692, 'completion_time': 0.12168616, 'completion_tokens_details': None, 'prompt_time': 0.03158785, 'prompt_tokens_details': None, 'queue_time': 0.0556591, 'total_time': 0.15327401}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4387d3edbb', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b2b87-f2e5-7df0-886e-2c516d4c5b15-0', tool_calls=[{'name': 'multiply', 'args': {'a': 200, 'b': 110}, 'id': 'zfrrbqcpe', 'type': 'tool_call'}, {'name': 'multiply', 'args': {'a': 200, 'b': 110}, 'id': '4trym1z5j', 'type': 'tool_call'}, {'name': 'multiply', 'args': {'a': 200, 'b': 110}, 'id': 'k70xbdkyr', 'type': 'tool_call'}, {'name': 'multiply', 'args': {'a': 200, 'b': 110}, 'id': '6xvkwvjfw', 'type': 'tool_call'}, {'name': 'multiply', 'args': {'a': 200, 'b': 110}, 'id': '1jbmjdnpp', 'type': 'tool_call'}, {'name': 'divide', 'args': {'a': 10, 'b': 2}, 'id': 'p1gm791n6', 'type': 'tool_call'}, {'name': 'add', 'args': {'a': 15, 'b': 25}, 'id': 'c05jc43th', 'type': 'tool_call'}], usage_metadata={'input_tokens': 566, 'output_tokens': 126, 'total_tokens': 692}), ToolMessage(content='22000', name='multiply', id='99254b4e-93f6-4322-82bd-e9e313c0b5f4', tool_call_id='zfrrbqcpe'), ToolMessage(content='22000', name='multiply', id='4f5d9ecf-ff91-4b9b-ac14-b3ce15bb2239', tool_call_id='4trym1z5j'), ToolMessage(content='22000', name='multiply', id='33222cf8-02c7-4372-8e7a-f992cb3d523e', tool_call_id='k70xbdkyr'), ToolMessage(content='22000', name='multiply', id='ed1fd066-90c3-420f-92ec-879abb3a8ece', tool_call_id='6xvkwvjfw'), ToolMessage(content='22000', name='multiply', id='791c5db0-d26f-422d-91ea-849826b11f82', tool_call_id='1jbmjdnpp'), ToolMessage(content='5.0', name='divide', id='49a136ea-74b6-4879-9fd7-f61a2179ca4a', tool_call_id='p1gm791n6'), ToolMessage(content='40', name='add', id='db603b3f-4d29-474c-8789-b61c58c7e323', tool_call_id='c05jc43th'), HumanMessage(content='Divide 10 and 2', additional_kwargs={}, response_metadata={}, id='045084ff-eec1-46b2-bbb4-b0c3ceddd9de')]}, next=('assistance',), config={'configurable': {'thread_id': '222', 'checkpoint_ns': '', 'checkpoint_id': '1f0db26b-35ca-67ec-8012-6070ac26e6f8'}}, metadata={'source': 'loop', 'step': 18, 'parents': {}}, created_at='2025-12-17T08:59:31.291953+00:00', parent_config={'configurable': {'thread_id': '222', 'checkpoint_ns': '', 'checkpoint_id': '1f0db26b-35c3-62d7-8011-4396f6d1a76e'}}, tasks=(PregelTask(id='3aaeb4a9-150d-8a05-0291-7ac49712c554', name='assistance', path=('__pregel_pull', 'assistance'), error=None, interrupts=(), state=None, result=None),), interrupts=())"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "41b393dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Pregel.get_state_history at 0x0000020EE875C720>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### To Check all Checkpoints\n",
    "\n",
    "history = graph_builder.get_state_history(config)\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ae76d2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Divide 10 and 2\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  divide (nwhe10s87)\n",
      " Call ID: nwhe10s87\n",
      "  Args:\n",
      "    a: 10\n",
      "    b: 2\n",
      "  divide (fmaynbwkr)\n",
      " Call ID: fmaynbwkr\n",
      "  Args:\n",
      "    a: 10\n",
      "    b: 2\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: divide\n",
      "\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "### Contonue the Exucution\n",
    "for event in graph_builder.stream(None,config,stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()\n",
    "    \n",
    "\n",
    "##Why pass as a None --> Because we already pass msg to the llm and tool \n",
    "\n",
    "## When Human Interact with llm then llm calls the tools and exucte the input --> when we  pass the \"None\"(interact with human) LLM provide answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9855d947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('assistance',)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Again check the State where exucution is paused\n",
    "## To see which state is to be exucute next \n",
    "state = graph_builder.get_state(config)\n",
    "state.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d786be11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: divide\n",
      "\n",
      "5.0\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  divide (1rnaghq9m)\n",
      " Call ID: 1rnaghq9m\n",
      "  Args:\n",
      "    a: 10\n",
      "    b: 0\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mZeroDivisionError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[124]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m### Contonue the Exucution\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraph_builder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpretty_print\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m##Why pass as a None --> Because we already pass msg to the llm and tool \u001b[39;00m\n\u001b[32m      7\u001b[39m \n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m## When Human Interact with llm then llm calls the tools and exucte the input --> when we  pass the \"None\"(interact with human) LLM provide answer\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\LangGraphSeries\\module01\\venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:2643\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2641\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2642\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2643\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2644\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2645\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2646\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2647\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2650\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2653\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\LangGraphSeries\\module01\\venv\\Lib\\site-packages\\langgraph\\pregel\\_runner.py:167\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    165\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\LangGraphSeries\\module01\\venv\\Lib\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\LangGraphSeries\\module01\\venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:656\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    654\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    658\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\LangGraphSeries\\module01\\venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:400\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\LangGraphSeries\\module01\\venv\\Lib\\site-packages\\langgraph\\prebuilt\\tool_node.py:799\u001b[39m, in \u001b[36mToolNode._func\u001b[39m\u001b[34m(self, input, config, runtime)\u001b[39m\n\u001b[32m    797\u001b[39m input_types = [input_type] * \u001b[38;5;28mlen\u001b[39m(tool_calls)\n\u001b[32m    798\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[32m--> \u001b[39m\u001b[32m799\u001b[39m     outputs = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexecutor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_one\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_calls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_runtimes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    801\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    803\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._combine_tool_outputs(outputs, input_type)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\LangGraphSeries\\module01\\venv\\Lib\\concurrent\\futures\\_base.py:619\u001b[39m, in \u001b[36mExecutor.map.<locals>.result_iterator\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[32m    617\u001b[39m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[32m    618\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m619\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    620\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    621\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs.pop(), end_time - time.monotonic())\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\LangGraphSeries\\module01\\venv\\Lib\\concurrent\\futures\\_base.py:317\u001b[39m, in \u001b[36m_result_or_cancel\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    316\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m317\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    318\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    319\u001b[39m         fut.cancel()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\LangGraphSeries\\module01\\venv\\Lib\\concurrent\\futures\\_base.py:456\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    455\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    458\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\LangGraphSeries\\module01\\venv\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\LangGraphSeries\\module01\\venv\\Lib\\concurrent\\futures\\thread.py:58\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.future.set_exception(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\LangGraphSeries\\module01\\venv\\Lib\\site-packages\\langchain_core\\runnables\\config.py:551\u001b[39m, in \u001b[36mContextThreadPoolExecutor.map.<locals>._wrapped_fn\u001b[39m\u001b[34m(*args)\u001b[39m\n\u001b[32m    550\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_wrapped_fn\u001b[39m(*args: Any) -> T:\n\u001b[32m--> \u001b[39m\u001b[32m551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontexts\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\LangGraphSeries\\module01\\venv\\Lib\\site-packages\\langgraph\\prebuilt\\tool_node.py:1010\u001b[39m, in \u001b[36mToolNode._run_one\u001b[39m\u001b[34m(self, call, input_type, tool_runtime)\u001b[39m\n\u001b[32m   1006\u001b[39m config = tool_runtime.config\n\u001b[32m   1008\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._wrap_tool_call \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1009\u001b[39m     \u001b[38;5;66;03m# No wrapper - execute directly\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1010\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_tool_sync\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[38;5;66;03m# Define execute callable that can be called multiple times\u001b[39;00m\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute\u001b[39m(req: ToolCallRequest) -> ToolMessage | Command:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\LangGraphSeries\\module01\\venv\\Lib\\site-packages\\langgraph\\prebuilt\\tool_node.py:959\u001b[39m, in \u001b[36mToolNode._execute_tool_sync\u001b[39m\u001b[34m(self, request, input_type, config)\u001b[39m\n\u001b[32m    956\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m    958\u001b[39m     \u001b[38;5;66;03m# Error is handled - create error ToolMessage\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m959\u001b[39m     content = \u001b[43m_handle_tool_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflag\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_tool_errors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    960\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ToolMessage(\n\u001b[32m    961\u001b[39m         content=content,\n\u001b[32m    962\u001b[39m         name=call[\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    963\u001b[39m         tool_call_id=call[\u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    964\u001b[39m         status=\u001b[33m\"\u001b[39m\u001b[33merror\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    965\u001b[39m     )\n\u001b[32m    967\u001b[39m \u001b[38;5;66;03m# Process successful response\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\LangGraphSeries\\module01\\venv\\Lib\\site-packages\\langgraph\\prebuilt\\tool_node.py:424\u001b[39m, in \u001b[36m_handle_tool_error\u001b[39m\u001b[34m(e, flag)\u001b[39m\n\u001b[32m    422\u001b[39m     content = flag\n\u001b[32m    423\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(flag):\n\u001b[32m--> \u001b[39m\u001b[32m424\u001b[39m     content = \u001b[43mflag\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore [assignment, call-arg]\u001b[39;00m\n\u001b[32m    425\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    426\u001b[39m     msg = (\n\u001b[32m    427\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGot unexpected type of `handle_tool_error`. Expected bool, str \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    428\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mor callable. Received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mflag\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    429\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\LangGraphSeries\\module01\\venv\\Lib\\site-packages\\langgraph\\prebuilt\\tool_node.py:381\u001b[39m, in \u001b[36m_default_handle_tool_errors\u001b[39m\u001b[34m(e)\u001b[39m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, ToolInvocationError):\n\u001b[32m    380\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m e.message\n\u001b[32m--> \u001b[39m\u001b[32m381\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\LangGraphSeries\\module01\\venv\\Lib\\site-packages\\langgraph\\prebuilt\\tool_node.py:916\u001b[39m, in \u001b[36mToolNode._execute_tool_sync\u001b[39m\u001b[34m(self, request, input_type, config)\u001b[39m\n\u001b[32m    914\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    915\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m916\u001b[39m         response = \u001b[43mtool\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    917\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    918\u001b[39m         \u001b[38;5;66;03m# Filter out errors for injected arguments\u001b[39;00m\n\u001b[32m    919\u001b[39m         injected = \u001b[38;5;28mself\u001b[39m._injected_args.get(call[\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\LangGraphSeries\\module01\\venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:605\u001b[39m, in \u001b[36mBaseTool.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    597\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    598\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    599\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    602\u001b[39m     **kwargs: Any,\n\u001b[32m    603\u001b[39m ) -> Any:\n\u001b[32m    604\u001b[39m     tool_input, kwargs = _prep_run_args(\u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m605\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\LangGraphSeries\\module01\\venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:931\u001b[39m, in \u001b[36mBaseTool.run\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    929\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_to_raise:\n\u001b[32m    930\u001b[39m     run_manager.on_tool_error(error_to_raise)\n\u001b[32m--> \u001b[39m\u001b[32m931\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error_to_raise\n\u001b[32m    932\u001b[39m output = _format_output(content, artifact, tool_call_id, \u001b[38;5;28mself\u001b[39m.name, status)\n\u001b[32m    933\u001b[39m run_manager.on_tool_end(output, color=color, name=\u001b[38;5;28mself\u001b[39m.name, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\LangGraphSeries\\module01\\venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:897\u001b[39m, in \u001b[36mBaseTool.run\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    895\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m config_param := _get_runnable_config_param(\u001b[38;5;28mself\u001b[39m._run):\n\u001b[32m    896\u001b[39m         tool_kwargs |= {config_param: config}\n\u001b[32m--> \u001b[39m\u001b[32m897\u001b[39m     response = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mtool_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtool_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.response_format == \u001b[33m\"\u001b[39m\u001b[33mcontent_and_artifact\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    899\u001b[39m     msg = (\n\u001b[32m    900\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mSince response_format=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mcontent_and_artifact\u001b[39m\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    901\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33ma two-tuple of the message content and raw tool output is \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    902\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mexpected. Instead, generated response is of type: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    903\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(response)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    904\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\LangGraphSeries\\module01\\venv\\Lib\\site-packages\\langchain_core\\tools\\structured.py:93\u001b[39m, in \u001b[36mStructuredTool._run\u001b[39m\u001b[34m(self, config, run_manager, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m config_param := _get_runnable_config_param(\u001b[38;5;28mself\u001b[39m.func):\n\u001b[32m     92\u001b[39m         kwargs[config_param] = config\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m msg = \u001b[33m\"\u001b[39m\u001b[33mStructuredTool does not support sync invocation.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(msg)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[112]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mdivide\u001b[39m\u001b[34m(a, b)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdivide\u001b[39m(a:\u001b[38;5;28mint\u001b[39m,b:\u001b[38;5;28mint\u001b[39m)->\u001b[38;5;28mint\u001b[39m:\n\u001b[32m     24\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Divide a and b\u001b[39;00m\n\u001b[32m     25\u001b[39m \n\u001b[32m     26\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     29\u001b[39m \n\u001b[32m     30\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43ma\u001b[49m\u001b[43m/\u001b[49m\u001b[43mb\u001b[49m\n",
      "\u001b[31mZeroDivisionError\u001b[39m: division by zero",
      "During task with name 'tools' and id '3e159e95-7339-a2ff-e854-2dff0888fe7d'"
     ]
    }
   ],
   "source": [
    "### Contonue the Exucution\n",
    "for event in graph_builder.stream(None,config,stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()\n",
    "    \n",
    "\n",
    "##Why pass as a None --> Because we already pass msg to the llm and tool \n",
    "\n",
    "## When Human Interact with llm then llm calls the tools and exucte the input --> when we  pass the \"None\"(interact with human) LLM provide answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc676bb0",
   "metadata": {},
   "source": [
    "# Create Another Project After "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783fe263",
   "metadata": {},
   "source": [
    "#### edit the Human FeedBack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "128e475b",
   "metadata": {},
   "outputs": [],
   "source": [
    "threads = {\n",
    "    \"configurable\":\n",
    "        {\"thread_id\":\"222\"}\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6d266e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Divide 10 and 2\n"
     ]
    }
   ],
   "source": [
    "### Create a Human Message\n",
    "from pprint import pprint\n",
    "message = {\"messages\":HumanMessage(content=\"Divide 10 and 2\")}\n",
    "\n",
    "for event in graph_builder.stream(message,threads,stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f686bdaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('assistance',)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## To see which state is to be exucute next \n",
    "state = graph_builder.get_state(threads)\n",
    "state.next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1c161e",
   "metadata": {},
   "source": [
    "### Update the State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bdb51e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '222',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f0db06f-1f5f-683a-8004-575b29baf132'}}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.update_state(threads,{\"messages\":[HumanMessage(content=\"Plz add 15 and 25\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "38079621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Divide 10 and 2\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Plz add 15 and 25\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Divide 10 and 2\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Plz add 15 and 25\n"
     ]
    }
   ],
   "source": [
    "### See the new State\n",
    "## To see which state is to be exucute next \n",
    "new_state = graph_builder.get_state(threads).values\n",
    "\n",
    "for m in new_state[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "78fe8696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Plz add 15 and 25\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  divide (4gcyf591g)\n",
      " Call ID: 4gcyf591g\n",
      "  Args:\n",
      "    a: 10\n",
      "    b: 2\n",
      "  add (xbr2jmftb)\n",
      " Call ID: xbr2jmftb\n",
      "  Args:\n",
      "    a: 15\n",
      "    b: 25\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "### Contonue the Exucution\n",
    "for event in graph_builder.stream(None,threads,stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()\n",
    "    \n",
    "\n",
    "##Why pass as a None --> Because we already pass msg to the llm and tool \n",
    "\n",
    "## When Human Interact with llm then llm calls the tools and exucte the input --> when we  pass the \"None\"(interact with human) LLM provide answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f367347",
   "metadata": {},
   "source": [
    "##### Update the msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "26a381e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "threads1 = {\n",
    "    \"configurable\":\n",
    "        {\"thread_id\":\"786\"}\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "829acd90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Divide 10 and 2\n"
     ]
    }
   ],
   "source": [
    "### Create a Human Message\n",
    "from pprint import pprint\n",
    "message = {\"messages\":HumanMessage(content=\"Divide 10 and 2\")}\n",
    "\n",
    "for event in graph_builder.stream(message,threads1,stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "428334f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('assistance',)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## To see which state is to be exucute next \n",
    "state = graph_builder.get_state(threads)\n",
    "state.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0acf5090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '786',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f0db26b-c925-6508-8009-22178f55d6eb'}}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.update_state(threads1,{\"messages\":[HumanMessage(content=\"plz multiply 5 and 10\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "82b121ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Plz add 15 and 25\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "plz multiply 100 and 2000\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "plz multiply 100 and 2000\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "plz multiply 100 and 2000\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "plz multiply 100 and 2000\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "plz multiply 100 and 2000\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<multiply>{\"a\": 100, \"b\": 2000}</multiply>\n",
      "<multiply>{\"a\": 100, \"b\": 2000}</multiply>\n",
      "<multiply>{\"a\": 100, \"b\": 2000}</multiply>\n",
      "<multiply>{\"a\": 100, \"b\": 2000}</multiply>\n",
      "<multiply>{\"a\": 100, \"b\": 2000}</multiply>\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Divide 10 and 2\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "plz multiply 5 and 10\n"
     ]
    }
   ],
   "source": [
    "### See the new State\n",
    "## To see which state is to be exucute next \n",
    "new_state = graph_builder.get_state(threads1).values\n",
    "\n",
    "for m in new_state[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f36c98d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<multiply>{\"a\": 5, \"b\": 10}</multiply>\n"
     ]
    }
   ],
   "source": [
    "### Contonue the Exucution\n",
    "for event in graph_builder.stream(None,threads1,stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()\n",
    "    \n",
    "\n",
    "##Why pass as a None --> Because we already pass msg to the llm and tool \n",
    "\n",
    "## When Human Interact with llm then llm calls the tools and exucte the input --> when we  pass the \"None\"(interact with human) LLM provide answer\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
